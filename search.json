[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Supplemental Materials: Integrating Multi-Omics with Environmental data for Precision Health",
    "section": "",
    "text": "Preface\nIntegrating environmental data with biological data from multiple omics datasets can help provide unprecedented insights into the complex interplay of environment and biology. Joint analysis of environment and multi-omics can provide a more comprehensive picture of individual health and disease than individually analyzing datasets. However, to harness the full potential of using multi-omics data to understand environmental and biological drivers of disease, researchers need a robust framework for understanding how and why to perform different multiomic integration techniques.\nThis book is intended as a resource for researchers aiming to incorporate omics datasets to understand how environmental or biological factors impact human health and disease. We aim to explain the concepts, techniques, and methodologies that allow researchers to fully leverage the information in multidimensional datasets to obtain biologically relevant and actionable insights into environmental and biological impacts on disease.\nThis book has three sections corresponding to each column shown in Figure 1. In Chapter 2, we provide an example of high dimensional mediation with early, intermediate, and late integration, as shown in the first column of Figure 1. In Chapter 3, we provide an example of mediation with latent factors, a two-step approach that first uses dimensionality reduction on the omics datasets and then performs mediation on the resulting factors, as shown in the second column of Figure 1. In Chapter 4, we provide an example of quasi/intermediate integration, an approach where information on environmental factors and information on multiple omic layers are analyzed jointly in a single unified analysis, as shown in column 3 of Figure 1.\n\n\n\nFigure 1: Conceptual diagram illustrating the analytic framework for mediation analysis with multiple omic layers."
  },
  {
    "objectID": "intro.html#r-packages",
    "href": "intro.html#r-packages",
    "title": "1  Introduction",
    "section": "1.1 R Packages",
    "text": "1.1 R Packages\nBefore starting, you will need the following R packages.\nThe following is a list of packages that are used throughout this book that need to be loaded before any analysis. A complete list of all the packages used in the book can be found in Chapter 5.\n\n\nCode\n# General Packages:\nlibrary(tidyverse)\nlibrary(tools)\nlibrary(parallel)\nlibrary(boot) \nlibrary(table1)\n# Packages for Plotting:\nlibrary(ggplot2)\nlibrary(cowplot) \nlibrary(ComplexHeatmap) \nlibrary(ggh4x)\n# Packages for High Dimensional Mediation:\nlibrary(HIMA)\nlibrary(xtune)\nlibrary(RMediation)\nlibrary(glmnet)\n# Packages for Mediation with Latent Factors:\nlibrary(r.jive)\n# Packages for Quasi-mediation:\nlibrary(LUCIDus)\nlibrary(mclust)\nlibrary(networkD3)\nlibrary(plotly)\nlibrary(htmlwidgets)\nlibrary(glasso)\nlibrary(nnet)\nlibrary(progress)\nlibrary(jsonlite)\n\n\nIn order to replicate the style of the figures in this book, you will also have to set the ggplot theme:\n\n\nCode\nggplot2::theme_set(cowplot::theme_cowplot())"
  },
  {
    "objectID": "intro.html#custom-functions",
    "href": "intro.html#custom-functions",
    "title": "1  Introduction",
    "section": "1.2 Custom Functions",
    "text": "1.2 Custom Functions\nThe analyses in this book rely on several custom functions. The code for functions are provided in Chapter 6."
  },
  {
    "objectID": "intro.html#the-data",
    "href": "intro.html#the-data",
    "title": "1  Introduction",
    "section": "1.3 The Data",
    "text": "1.3 The Data\nThe data used in this project is based off of simulated data from the Human Early Life Exposome (HELIX) cohort (Vrijheid et al. 2014). The data was simulated for one exposure, five omics layers, and one continuous outcome (after publication, this data will be available on github). The format of this data is a named list with 6 elements. It includes separate numeric matrices for each of the 5 omics layers, as well as the exposure and phenotype data. In all datasets in the list, the rows represent individuals and the columns represent omics features. In this analysis, the exposure and outcome are:\n\n\nExposure: hs_hg_m_resid, representing maternal mercury levels\n\nOutcome: ck18_scaled, representing child liver enzyme levels, a major risk factor for non-alcoholic fatty liver disease (NAFLD).\n\nYou can read this data into R using the following code:\n\n\nCode\n# Load simulated data\nsimulated_data &lt;- read_rds(fs::path(dir_data_hg, \"simulated_HELIX_data_2.RDS\")) \n\n# Define exposure and outcome name\ncovars &lt;- c(\"e3_sex_None\", \"hs_child_age_yrs_None\")\n\n# Extract exposure and outcome data\n# outcomes &lt;- simulated_data[[\"phenotype\"]]\nexposure &lt;- simulated_data[[\"phenotype\"]]$hs_hg_m_scaled\noutcome  &lt;- simulated_data[[\"phenotype\"]]$ck18_scaled\n\n# Get numeric matrix of covariates \ncovs &lt;- simulated_data[[\"phenotype\"]][covars] \ncovs$e3_sex_None &lt;- if_else(covs$e3_sex_None == \"male\", 1, 0)\n\n\n# create list of omics data \nomics_lst &lt;- simulated_data[-which(names(simulated_data) == \"phenotype\")]\n\n# Create data frame of omics data\nomics_df &lt;- omics_lst %&gt;% \n  purrr::map(~as_tibble(.x, rownames = \"name\")) %&gt;%\n  purrr::reduce(left_join, by = \"name\") %&gt;%\n  column_to_rownames(\"name\")\n\n\n\n1.3.1 Descriptive Statistics\nTable 1.1 shows the summary statistics for the exposure and phenotype data in this analysis.\n\n\nCode\ntable1::table1(~., data = simulated_data[[\"phenotype\"]][,-1])\n\n\n\n\n\n\nTable 1.1: Descriptive Statistics for the Simulated Variables\n\n\n\n\n\n\n\nOverall\n(N=420)\n\n\n\n\nhs_child_age_yrs_None\n\n\n\nMean (SD)\n7.22 (1.04)\n\n\nMedian [Min, Max]\n7.18 [3.93, 10.9]\n\n\nhs_hg_m_scaled\n\n\n\nMean (SD)\n-0.0148 (1.02)\n\n\nMedian [Min, Max]\n-0.0433 [-2.73, 3.34]\n\n\nck18_scaled\n\n\n\nMean (SD)\n-0.0511 (1.03)\n\n\nMedian [Min, Max]\n0.00883 [-3.56, 3.09]\n\n\ne3_sex_None\n\n\n\nfemale\n192 (45.7%)\n\n\nmale\n228 (54.3%)\n\n\nh_fish_preg_Ter\n\n\n\n1\n233 (55.5%)\n\n\n2\n88 (21.0%)\n\n\n3\n99 (23.6%)\n\n\n\n\n\n\n\n\n\n\n\n1.3.2 Mercury exposure and childhood MAFLD risk\n\n\nCode\nlm_res &lt;- lm(ck18_scaled ~ hs_hg_m_scaled + \n     e3_sex_None +\n     hs_child_age_yrs_None,\n   data = simulated_data[[\"phenotype\"]])\n\nsummary(lm_res)\n\n\nIn the simulated data, each 1 standard deviation increase in maternal mercury was associated with a 0.11 standard deviation increase in CK18 enzymes (Figure 1.1; p=0.02), after adjusting for child age and child sex.\n\n\nCode\nggplot(data = simulated_data[[\"phenotype\"]], \n       aes(x = hs_hg_m_scaled, y = ck18_scaled)) + \n  geom_point() +\n  stat_smooth(method = \"lm\",\n              formula = y ~ x ,\n              geom = \"smooth\") +\n  xlab(\"Maternal Mercury Exposure (Scaled)\") +\n  ylab(\"CK-18 Levels (Scaled)\")\n\n\n\n\n\nFigure 1.1: Association between maternal mercury and CK18 in the Simulated Data\n\n\n\n\n\n\n\n1.3.3 Correlation of omics features\nFigure 1.2 shows the correlation within and between the omics layers in the simulated data.\n\n\nCode\n# Change omics list elements to dataframes\nomics_df &lt;- purrr::map(omics_lst, ~as_tibble(.x, rownames = \"name\")) %&gt;%\n  purrr::reduce(left_join, by = \"name\") %&gt;%\n  column_to_rownames(\"name\")\n\nmeta_df &lt;- imap_dfr(purrr::map(omics_lst, ~as_tibble(.x)),\n                    ~tibble(omic_layer = .y, ftr_name = names(.x)))\n\n# Correlation Matrix\ncormat &lt;- cor(omics_df, method = \"pearson\")\n\n# Annotations\nannotation &lt;- data.frame(\n  ftr_name = colnames(cormat),\n  index = 1:ncol(cormat)) %&gt;%\n  left_join(meta_df, by = \"ftr_name\") %&gt;%\n  mutate(omic_layer = toTitleCase(omic_layer))\n\n# Make Plot\nHeatmap(cormat, \n        row_split = annotation$omic_layer,\n        column_split = annotation$omic_layer,\n        show_row_names = FALSE,\n        show_column_names = FALSE, \n        column_title_gp = gpar(fontsize = 12),\n        row_title_gp = gpar(fontsize = 12),\n        heatmap_legend_param = list(title = \"Correlation\"))\n\n\n\n\n\nFigure 1.2: Heatmap illustrating the correlation of molecular features within and between different omics layers.\n\n\n\n\n\n\n\n\nVrijheid, Martine, Rémy Slama, Oliver Robinson, Leda Chatzi, Muireann Coen, Peter van den Hazel, Cathrine Thomsen, et al. 2014. “The Human Early-Life Exposome (HELIX): Project Rationale and Design.” Journal Article. Environmental Health Perspectives 122 (6): 535–44. https://doi.org/10.1289/ehp.1307204."
  },
  {
    "objectID": "HIMA.html#early-integration",
    "href": "HIMA.html#early-integration",
    "title": "2  High Dimensional Mediation",
    "section": "2.1 Early integration",
    "text": "2.1 Early integration\nHigh dimensional mediation with early multiomic integration (Figure 1, panel a) identified differentially methylated CpG sites, gene transcript clusters, metabolites, and proteins which mediated associations of prenatal mercury with MAFLD risk in adolescents (Figure 2.1). Combining all omics layers before analysis identifies the strongest mediating feature across all omics layers without accounting for the differences in underlying correlation structure. For this analysis, we used High Dimensional Mediation Analysis (HIMA), a penalization-based mediation method implemented in the R package HIMA (Zhang et al. 2016). The full code for the hima_early_integration function is provided in Section 6.1.1 and plot_hima function is provided in Section 6.1.4.\n\n\nCode\n# Run Analysis\nresult_hima_early &lt;- hima_early_integration(exposure = exposure,\n                                            outcome = outcome, \n                                            omics_lst = omics_lst, \n                                            covs = covs,\n                                            Y.family = \"gaussian\", \n                                            M.family = \"gaussian\")\n# Plot Result\n(plot_hima(result_hima_early))\n\n\n\n\n\nFigure 2.1: High dimensional mediation analysis with early integration and multiple omic layers identifies individual molecular features linking maternal mercury with childhood liver injury. Alpha represents the coefficient estimates of the exposure to the mediator, Beta indicates the coefficient estimates of the mediators to the outcome, and TE (%) represents the percent total effect mediated calculated as alpha*beta/gamma."
  },
  {
    "objectID": "HIMA.html#intermediate-integration",
    "href": "HIMA.html#intermediate-integration",
    "title": "2  High Dimensional Mediation",
    "section": "2.2 Intermediate Integration",
    "text": "2.2 Intermediate Integration\nHigh dimensional mediation with intermediate multiomic integration (Figure 1, panel b) identified differentially methylated CpG sites, gene transcript clusters, and miRNA which mediated associations of prenatal mercury with MAFLD risk in adolescents (Figure 2.2). Combining all omics layers before analysis identifies the strongest mediating feature across all omics layers without accounting for the differences in underlying correlation structure.\nFor this analysis, we use a novel two-step approach that incorporates feature level metadata to inform on feature selection using xtune (Zeng, Thomas, and Lewinger 2021), an approach that allows for feature-specific penalty parameters and, in this example, performs a group-lasso-type shrinkage within each omic dataset. This analysis is similar in theory to HIMA, with the difference being that for this method the penalization can vary across each of the omic layers. This analysis was based on the product of coefficients method for mediation and was performed in three steps:\n\nRegression 1 (linear regression):\n\nFirst, we performed independent linear regression models for all exposure-mediator associations to get the exposure mediator coefficient:\n\\[\\begin{equation}\nm_i = a_0 + a_1 \\times x\n\\label{eq:reg1}\n\\end{equation}\\]\n   Where \\(x\\) is the exposure and \\(m_i\\) is each mediator.\n\nRegression 2 (group lasso):\n\nSecond, we performed a single group lasso regression for the mediator outcome associations, adjusting for the exposure, using the R package xtune (He and Zeng 2023). This step provided coefficients for each of the mediator outcome associations. We used bootstrapping to obtain the standard error of the coefficients from the group lasso regression for each of the mediator coefficients.\n\\[\\begin{equation}\ny = b_0 + b_1 \\times x + b_{2_i} \\times M\n\\label{eq:reg2}\n\\end{equation}\\]\n   Where \\(y\\) is the outcome, \\(x\\) is the exposure, \\(M\\) is the mediator matrix with corresponding estimate \\(b_{2_i}\\). The bootstrapped standard error (se) of \\(b_{2_i}\\) is used for calculating mediation confidence intervals.\n\nCalculate mediation confidence interval for mediator ( i ):\n\nFinally, for each omic feature, we calculated the mediation effect and 95% confidence intervals using the R package RMediation, which is based on the distribution-of-the-product method (Tofighi and MacKinnon 2011).\n\\[\\begin{align}\n\\alpha &= a_1 \\label{eq:alpha}\\\\\n\\text{se of } \\alpha &= \\text{se of } a_1 \\label{eq:se_alpha}\\\\\n\\beta &= b_{2_i} \\label{eq:beta}\\\\\n\\text{se of } \\beta &= \\text{se of } b_{2_i} \\label{eq:se_beta}\n\\end{align}\\]\nThe full code for the hima_intermediate_integration function is provided in Section 6.1.2 and plot_hima function is provided in Section 6.1.4. Note: For the actual analysis, we would normally set n_boot to a higher value (1000 or more). In the example code, it is set to 12 to improve the speed of the function.\n\n\nCode\n# Run Analysis\nresult_hima_intermediate &lt;- hima_intermediate_integration(\n  omics_lst = omics_lst,\n  covs = covs,\n  outcome = outcome,\n  exposure = exposure,\n  n_boot = 12,\n  Y.family = \"gaussian\")\n\n\n\n\nCode\n# plot\n(plot_hima(result_hima_intermediate))\n\n\n\n\n\nFigure 2.2: High dimensional mediation analysis with intermediate integration and multiple omic layers identifies individual molecular features linking maternal mercury with childhood liver injury. Alpha represents the coefficient estimates of the exposure to the mediator, Beta indicates the coefficient estimates of the mediators to the outcome, and TE (%) represents the percent total effect mediated calculated as alpha*beta/gamma."
  },
  {
    "objectID": "HIMA.html#late-integration",
    "href": "HIMA.html#late-integration",
    "title": "2  High Dimensional Mediation",
    "section": "2.3 Late integration",
    "text": "2.3 Late integration\nHigh dimensional mediation with late multiomic integration (Figure 1, panel c) identified differentially methylated CpG sites, gene transcript clusters, and miRNA which mediated associations of prenatal mercury with MAFLD risk in adolescents (Figure 2.3). High dimensional mediation with late multiomic integration differs from the early and intermediate integration in that each omics layer is analyzed individually. Thus, this approach does not condition on features within the other omics layers in the analysis.\nCombining all omics layers before analysis identifies the strongest mediating feature across all omics layers without accounting for the differences in underlying correlation structure. For this analysis, we used High Dimensional Mediation Analysis (HIMA), a penalization-based mediation method implemented in the R package HIMA (Zhang et al. 2016). The full code for the hima_late_integration function is provided in Section 6.1.3 and plot_hima function is provided in Section 6.1.4.\n\n\nCode\n# Run Analysis\nresult_hima_late &lt;- hima_late_integration(exposure = exposure,\n                                          outcome = outcome, \n                                          omics_lst = omics_lst, \n                                          covs = covs, \n                                          Y.family = \"gaussian\", \n                                          M.family = \"gaussian\")\n\n# plot\n(plot_hima(result_hima_late))\n\n\n\n\n\nFigure 2.3: High dimensional mediation analysis with late integration and multiple omic layers identifies individual molecular features linking maternal mercury with childhood liver injury. Alpha represents the coefficient estimates of the exposure to the mediator, Beta indicates the coefficient estimates of the mediators to the outcome, and TE (%) represents the percent total effect mediated calculated as alpha*beta/gamma.\n\n\n\n\n\n\n\n\nHe, Jingxuan, and Chubing Zeng. 2023. “Xtune: Regularized Regression with Feature-Specific Penalties Integrating External Information.” Computer Program. https://github.com/JingxuanH/xtune.\n\n\nTofighi, D., and D. P. MacKinnon. 2011. “RMediation: An r Package for Mediation Analysis Confidence Intervals.” Journal Article. Behav Res Methods 43 (3): 692–700. https://doi.org/10.3758/s13428-011-0076-x.\n\n\nZeng, C., D. C. Thomas, and J. P. Lewinger. 2021. “Incorporating Prior Knowledge into Regularized Regression.” Journal Article. Bioinformatics 37 (4): 514–21. https://doi.org/10.1093/bioinformatics/btaa776.\n\n\nZhang, H., Y. Zheng, Z. Zhang, T. Gao, B. Joyce, G. Yoon, W. Zhang, et al. 2016. “Estimating and Testing High-Dimensional Mediation Effects in Epigenetic Studies.” Journal Article. Bioinformatics 32 (20): 3150–54. https://doi.org/10.1093/bioinformatics/btw351."
  },
  {
    "objectID": "Mediation_with_latent_fctrs.html#set-up-project-for-mediation-analysis-with-latent-factors",
    "href": "Mediation_with_latent_fctrs.html#set-up-project-for-mediation-analysis-with-latent-factors",
    "title": "3  Mediation with latent factors",
    "section": "3.1 Set up project for Mediation Analysis with Latent factors",
    "text": "3.1 Set up project for Mediation Analysis with Latent factors\n\n\nCode\nsource(fs::path(here::here(),\"project_setup\",\"directories.R\"))\nsource(fs::path(dir_proj, \"libraries.R\"))\nsource(fs::path(dir_proj, \"load_simu_data.R\"))\nsource(fs::path(dir_proj, \"functions\",\"mediation_with_latent_fctrs_functions.R\"))\nsource(fs::path(dir_proj, \"functions\",\"plot_mediation_lf_function.R\"))\n\n# options(knitr.table.format = \"html\")"
  },
  {
    "objectID": "Mediation_with_latent_fctrs.html#early-integration",
    "href": "Mediation_with_latent_fctrs.html#early-integration",
    "title": "3  Mediation with latent factors",
    "section": "3.2 Early integration",
    "text": "3.2 Early integration\nFor early integration, we used principal component analysis (PCA) as a dimensionality reduction step and selected the top i principal components which explained &gt;80% of the variance. Following the joint dimensionality reduction step, we used the r package HIMA (Zhang et al. 2016) to examine whether the variance components mediated associations of in utero mercury exposure with MAFLD. The full code for the med_lf_early function is provided in Section 6.2.1 and plot_med_lf function is provided in Section 6.2.4.\nIn this analysis, principal components explained &gt;80% of the variance in the combined omics datasets. Of these components, 7 significantly mediated the relationship between maternal mercury and childhood liver injury (Figure 3.1).\n\n3.2.1 HIMA Early Integration\n\n\nCode\n# Run Analysis\nresult_med_with_latent_fctrs_early &lt;-\n  med_lf_early(exposure, \n               outcome,\n               omics_lst, \n               covs = covs,\n               Y.family = \"gaussian\",\n               M.family = \"gaussian\",\n               fdr.level = 0.05)\n\n\n\n\n3.2.2 Plot Early Integration\n\n\nCode\n# Plot\n(plot_med_lf(result_med_with_latent_fctrs_early))\n\n\n\n\n\nFigure 3.1: Mediation analysis with latent factors and early integration identifies joing components which mediate the association between maternal mercury and childhood liver injury. Panel A shows the mediation effects, where Alpha represents the coefficient estimates of the exposure to the mediator, Beta indicates the coefficient estimates of the mediators to the outcome, and TE (%) represents the percent total effect mediated calculated as alpha*beta/gamma. Panel B shows the individual correlation between the omic feature and the joint component."
  },
  {
    "objectID": "Mediation_with_latent_fctrs.html#intermediate-integration",
    "href": "Mediation_with_latent_fctrs.html#intermediate-integration",
    "title": "3  Mediation with latent factors",
    "section": "3.3 Intermediate Integration",
    "text": "3.3 Intermediate Integration\nThe steps for intermediate integration start with performing a joint dimensionality reduction step using Joint and Individual Variance Explained (JIVE) (Lock et al. 2013). Following the joint dimensionality reduction step, we used the r package HIMA (Zhang et al. 2016) to examine whether the variance components mediated associations of in utero mercury exposure with MAFLD.\n\n3.3.1 Conduct JIVE and Perform Mediation Analysis\n\n3.3.1.1 Conduct JIVE\nFor this step, JIVE can estimate the optimal number of joint and individual ranks by changing the method argument in the function jive. For the simulated HELIX data, the optimal number, determined by setting method = \"perm\", was 22 joint ranks and 6, 9, 5, 5, and 8 ranks for the methylome, transcriptome, miRNA, proteome, and metabolome, respectively.\n\n\n3.3.1.2 Perform mediation analysis\nIn this analysis, 6 joint components, 1 transcriptome specific component significantly mediated the relationship between maternal mercury and childhood liver injury (Figure 3.2).The full code for the med_lf_intermediate function is provided in Section 6.2.2 and plot_med_lf function is provided in Section 6.2.4.\n\n\nCode\n# Run analysis with rnkJ and rankA provided\nresult_med_with_latent_fctrs_JIVE &lt;- \n  med_lf_intermediate(exposure, outcome,\n                      jive.rankJ = 22,\n                      jive.rankA = c(6, 9, 5, 5, 8),\n                      omics_lst,\n                      covs = covs, \n                      Y.family = \"gaussian\",\n                      M.family = \"gaussian\",\n                      fdr.level = 0.05)\n\n\n\n\n\n3.3.2 Plot Intermediate Integration\n\n\nCode\n(plot_med_lf(result_med_with_latent_fctrs_JIVE))\n\n\n\n\n\nFigure 3.2: Mediation analysis with latent factors and intermediate integration identifies joint and individual variance componets which mediate the association between maternal mercury and childhood liver injury. Panel A shows the mediation effects, where Alpha represents the coefficient estimates of the exposure to the mediator, Beta indicates the coefficient estimates of the mediators to the outcome, and TE (%) represents the percent total effect mediated calculated as alpha*beta/gamma. Panel B shows the individual correlation between the omic feature and the joint and individual components."
  },
  {
    "objectID": "Mediation_with_latent_fctrs.html#late-integration",
    "href": "Mediation_with_latent_fctrs.html#late-integration",
    "title": "3  Mediation with latent factors",
    "section": "3.4 Late integration",
    "text": "3.4 Late integration\nFor late integration, we used principal component analysis (PCA) as a dimensionality reduction step on each omics layer separately, and selected the top i principal components which explained &gt;80% of the variance. Following the dimensionality reduction step, we used the r package HIMA (Zhang et al. 2016) to examine whether the variance components mediated associations of in utero mercury exposure with MAFLD. The full code for the med_lf_late function is provided in Section 6.2.3 and plot_med_lf function is provided in Section 6.2.4\nThis analysis identified 2 methylated CpG sites, 1 miRNA, 1 protein and 2 expressed gene transcript clutesrs significantly mediated the association between mercury and MAFLD (Figure 3.3).\n\n3.4.1 HIMA Late Integration\n\n\nCode\nresult_med_with_latent_fctrs_late &lt;- med_lf_late(exposure, \n                                                outcome,\n                                                omics_lst, \n                                                covs = covs,\n                                                Y.family = \"gaussian\",\n                                                M.family = \"gaussian\",\n                                                fdr.level = 0.05)\n\n\n\n\n3.4.2 Plot Late Integration\n\n\nCode\n(plot_med_lf(result_med_with_latent_fctrs_late))\n\n\n\n\n\nFigure 3.3: Mediation analysis with latent factors and late integration identifies features in each omics layer individually which mediates the association between maternal mercury and childhood liver injury. Panel A shows the mediation effects, where Alpha represents the coefficient estimates of the exposure to the mediator, Beta indicates the coefficient estimates of the mediators to the outcome, and TE (%) represents the percent total effect mediated calculated as alpha*beta/gamma. Panel B shows the individual correlation between the omic feature and components."
  },
  {
    "objectID": "Mediation_with_latent_fctrs.html#pathway-analysis.",
    "href": "Mediation_with_latent_fctrs.html#pathway-analysis.",
    "title": "3  Mediation with latent factors",
    "section": "3.5 Pathway Analysis.",
    "text": "3.5 Pathway Analysis.\nFollowing mediation analysis, you can use the correlation p-values to perform pathway analysis with appropriate pathway analysis software.\n\n\n\n\nLock, E. F., K. A. Hoadley, J. S. Marron, and A. B. Nobel. 2013. “JOINT AND INDIVIDUAL VARIATION EXPLAINED (JIVE) FOR INTEGRATED ANALYSIS OF MULTIPLE DATA TYPES.” Journal Article. Ann Appl Stat 7 (1): 523–42. https://doi.org/10.1214/12-aoas597.\n\n\nZhang, H., Y. Zheng, Z. Zhang, T. Gao, B. Joyce, G. Yoon, W. Zhang, et al. 2016. “Estimating and Testing High-Dimensional Mediation Effects in Epigenetic Studies.” Journal Article. Bioinformatics 32 (20): 3150–54. https://doi.org/10.1093/bioinformatics/btw351."
  },
  {
    "objectID": "Quasi_mediation.html#early-integration",
    "href": "Quasi_mediation.html#early-integration",
    "title": "4  Integrated/Quasi-Mediation",
    "section": "4.1 Early Integration",
    "text": "4.1 Early Integration\nIn the Early Integration LUCID model, genomic/exposomic exposures \\(G\\), other omics data \\(Z\\) and phenotype trait \\(Y\\) are integrated through a latent categorical variable \\(X\\). Because \\(X\\) is an unobserved categorical variable, each category of \\(X\\) is interpreted as a latent cluster in the data, jointly defined by \\(G\\), \\(Z\\) and \\(Y\\). Let \\(G\\) be a \\(N \\times P\\) matrix with columns representing genetic/environmental exposures, and rows representing the observations; \\(Z\\) be a \\(N \\times M\\) matrix of omics data (for example, gene expression data, DNA methylation profiles and metabolomic data etc.) and \\(Y\\) be a \\(N\\)-length vector of phenotype trait. We further assume \\(G\\), \\(Z\\) and \\(Y\\) are measured through a prospective sampling procedure so we do not model the distribution of \\(G\\). All three measured components (\\(G\\), \\(Z\\) and \\(Y\\)) are linked by a latent variable \\(X\\) consisting of \\(K\\) categories. The distributions of \\(X\\) given \\(G\\), \\(Z\\) given \\(X\\) and \\(Y\\) given \\(X\\) are conditionally independent with each other. Let \\(f(\\cdot)\\) denote the probability mass functions (PMF) for categorical random variables or the probability density functions (PDF) for continuous random variables. The joint log-likelihood of the LUCID model is constructed as:\n\\[\n\\begin{aligned}\n         \\log L({\\Theta}) & = \\sum_{i = 1}^N \\log f({Z}_i, Y_i|{G}_i;{\\Theta}) \\\\\n         & = \\sum_{i = 1}^N \\log \\sum_{j = 1}^K f(X_i = j|{G}_i;{\\Theta}) f({Z}_i| X_i = j; {\\Theta}) f(Y_i|X_i = j; {\\Theta})\n    \\end{aligned}\n\\] where \\(\\Theta\\) is a generic notation for all parameters in Early Integration LUCID model. EM algorithm is implemented to estimate all parameters \\(\\Theta\\) iteratively until convergence, and \\(\\Theta\\) represents the \\(G\\) to \\(X\\), \\(X\\) to \\(Z\\), and \\(X\\) to \\(Y\\) associations,\nWe a-priori assigned the number of clusters to two. Early Integration LUCID estimates two omics specific clusters which represent an differential risks for the outcome. These omic profiles confer different risks of the outcome and represent each omics feature’s contribution to the exposure-outcome association.\n\n4.1.1 Analysis: Early Integration\n\n\nCode\n# Three omics layers, Methylation (CpG), Transcriptome and miRNA\nomics_df_analysis &lt;- omics_df %&gt;% \n  dplyr::select(contains(\"cg\"), contains(\"TC\"), contains(\"miR\"))\n\n\nWhen using estimate_lucid() to fit the Early Integration LUCID model, we specify lucid_model = \"early\", and K is an integer representing number of latent clusters. G, Z, Y are the inputs for exposure, omics data matrix, and the outcome, respectively.CoY are the covariates to be adjusted for the \\(X\\) to \\(Y\\) association and CoG are the covariates to be adjusted for the \\(G\\) to \\(X\\) association. We specify useY = TRUE to construct supervised LUCID model. Otherwise, useY = FALSE will construct unsupervised LUCID model. init_par = \"random\" means that we initiate the parameters with random guess. We specify family = \"normal\" since the outcome is continuous. If the outcome is binary, we would specify family = \"binary\".The full code for the sankey_early_integration function is provided in Section 6.3.1\n\n\nCode\nG = exposure %&gt;%\n  as.matrix()\nZ = omics_df_analysis %&gt;% \n  as.matrix()\n\nfit1 &lt;- estimate_lucid(lucid_model = \"early\",\n                       G = G,\n                       Z = Z,\n                       Y = outcome, \n                       K = 2,\n                       CoY = covs,\n                       CoG = covs,\n                       useY = TRUE,\n                       init_par = \"random\",\n                       family = \"normal\")\n## Initialize LUCID with random values from uniform distribution \n## Fitting Early Integration LUCID model (K = 2, Rho_G = 0, Rho_Z_Mu = 0, Rho_Z_Cov = 0) \n## .....Success: Early Integration LUCID converges!\n\n# Sankey Diagram\np1 &lt;- sankey_early_integration(fit1, text_size = 20)\n\n\n\n\n\nFigure 4.1: The Sankey Diagram for LUCID (Early Integration).\n\n\n\n\n4.1.2 Early Integration Results\nOmics profiles for each cluster determined using Early Integration LUCID. The full code for the plot_omics_profiles function is provided in Section 6.3.4\n\n\nCode\nplot_omics_profiles(fit1, \"Early\")"
  },
  {
    "objectID": "Quasi_mediation.html#intermediate-integration",
    "href": "Quasi_mediation.html#intermediate-integration",
    "title": "4  Integrated/Quasi-Mediation",
    "section": "4.2 Intermediate Integration",
    "text": "4.2 Intermediate Integration\nIn LUCID in parallel conducting intermediate integration, latent clusters \\(X_a\\) are estimated in each omics layer separately while integrating information from the genetic/environmental exposure \\(G\\) and the outcome \\(Y\\) by assuming no correlations across different omics layers. Let \\(G\\) be a \\(N \\times P\\) matrix with columns representing genetic/environmental exposures, and rows representing the observations; there is a collection of \\(m\\) omics data, denoted by \\(Z_1\\), . . . , \\(Z_a\\), . . . , \\(Z_m\\) with corresponding dimensions \\(p_1\\), . . . , \\(p_a\\), . . . , \\(p_m\\). Each omics data \\(Z_a\\) is summarized by a latent categorical variable \\(X_a\\), which contains \\(K_a\\) categories. Each category is interpreted as a latent cluster (or subgroup) for that particular omics layer and \\(Y\\) be a \\(N\\)-length vector of phenotype trait. Let \\(D\\) be the generic notation for all observed data. The log likelihood of LUCID with multiple latent variables is constructed below,\n\\[\n\\begin{aligned}\nl(\\boldsymbol{\\Theta} \\mid \\boldsymbol{D}) & =\\sum_{i=1}^{n} \\log f\\left(\\boldsymbol{Z}_{1 i}, \\ldots, \\boldsymbol{Z}_{m i}, \\boldsymbol{Y}_{i} \\mid \\boldsymbol{G}_{i} ; \\boldsymbol{\\Theta}\\right) \\\\\n& =\\sum_{i=1}^{n} \\log \\left[\\prod_{j_{1}=1}^{k_{1}} \\cdots \\prod_{j_{m}=1}^{k_{m}} f\\left(\\boldsymbol{Z}_{1 i}, \\ldots, \\boldsymbol{Z}_{m i}, X_{1 i}, \\ldots, X_{m i}, Y_{i} \\mid \\boldsymbol{G}_{i} ; \\boldsymbol{\\Theta}\\right)^{I\\left(X_{1 i}=j_{1}, \\ldots, X_{m i}=j_{m}\\right)}\\right] \\\\\n& =\\sum_{i=1}^{n} \\sum_{j_{1}=1}^{k_{1}} \\ldots \\sum_{j_{m}=1}^{k_{m}} I\\left(X_{1 i}=j_{1}, \\ldots, X_{m i}=j_{m}\\right) \\log f\\left(\\boldsymbol{Z}_{1 i}, \\ldots, \\boldsymbol{Z}_{m i}, X_{1 i}, \\ldots, X_{m i}, Y_{i} \\mid \\boldsymbol{G}_{i} ; \\boldsymbol{\\Theta}\\right) \\\\\n& =\\sum_{i=1}^{n} \\sum_{j_{1}=1}^{k_{1}} \\ldots \\sum_{j_{m}=1}^{k_{m}} I\\left(X_{1 i}=j_{1}, \\ldots, X_{m i}=j_{m}\\right) \\log \\phi\\left(Y_{i} \\mid X_{1 i}, \\ldots, X_{m i}, \\boldsymbol{\\delta}, \\sigma^{2}\\right) \\\\\n& +\\sum_{i=1}^{n} \\sum_{a=1}^{m} \\sum_{j_{1}=1}^{k_{1}} \\ldots \\sum_{j_{m}=1}^{k_{m}} I\\left(X_{1 i}=j_{1}, \\ldots, X_{m i}=j_{m}\\right) \\log \\phi\\left(\\boldsymbol{Z}_{a i} \\mid X_{a i}=j_{a}, \\boldsymbol{\\mu}_{a, j_{a}}, \\boldsymbol{\\Sigma}_{a, j_{a}}\\right) \\\\\n& +\\sum_{i=1}^{n} \\sum_{a=1}^{m} \\sum_{j_{1}=1}^{k_{1}} \\ldots \\sum_{j_{m}=1}^{k_{m}} I\\left(X_{1 i}=j_{1}, \\ldots, X_{m i}=j_{m}\\right) \\log S\\left(\\boldsymbol{X}_{a i}=j_{a} \\mid \\boldsymbol{G}_{i}, \\boldsymbol{\\beta}_{a}\\right)\n\\end{aligned}\n\\]\nThe log likelihood of LUCID in parallel is similar to that with Early integration LUCID. It is natural to follow the same principles of EM algorithm for Early integration LUCID with single intermediate variable.\nWe a-priori assigned the number of clusters for each omic layer to two. LUCID in parallel estimates omics specific clusters which represent an differential risks for the outcome within the layer. For each set of latent clusters within each omics layer, the corresponding omics profile was computed to identify the independent contribution of each omics layer to the exposure-outcome association.\nSet up the project for analysis.\nPrepare data for quasi-mediation analysis with LUCID in Parallel.\n\n\nCode\n# get feature meta data\nomics_lst_df &lt;- purrr::map(omics_lst, ~as_tibble(.x))\n  \nmeta_df &lt;- imap_dfr(omics_lst_df, ~tibble(omic_layer = .y, ftr_name = names(.x)))\n\n\nomics_lst_nmd_ftr = omics_lst\n# END NODE\n\n\n\n4.2.1 Analysis: Lucid with 3 omics layers in parallel\nWhen using estimate_lucid() to fit LUCID in parallel model, we specify lucid_model = \"parallel\", and K is a list with the same length as the number of omics layers and each element in the list is an integer representing number of latent clusters for the corresponding omics layer. max_itr = 200 means that the algorithm will stop when the iterations reaches 200 if still not reaching convergence. We specify useY = TRUE to construct supervised LUCID model. modelName is a vector of strings specifies the geometric model of omics data, the default modelName is “VVV”, but here “EEV” is more suitable.\n\n\n4.2.2 Sankey diagram\nThe full code for the plot_lucid_in_parellel_plotly function is provided in Section 6.3.2\n\n\nCode\np2 &lt;- plot_lucid_in_parallel_plotly(fit_reordered,\n                                      sankey_colors = sankey_colors,\n                                      text_size = 20,\n                                      n_z_ftrs_to_plot = c(7,7,7))\n\n\n\n\n\nFigure 4.2: The Sankey Diagram for LUCID in Parallel (Intermediate Integration).\n\n\n\n\n4.2.3 Omics profiles for each cluster predicted by LUCID\nThe full code for the plot_omics_profiles function is provided in Section 6.3.4\n\n\nCode\nplot_omics_profiles(fit_reordered, \"Intermediate\")"
  },
  {
    "objectID": "Quasi_mediation.html#late-integration",
    "href": "Quasi_mediation.html#late-integration",
    "title": "4  Integrated/Quasi-Mediation",
    "section": "4.3 Late Integration",
    "text": "4.3 Late Integration\nFor late integration, LUCID in serial is implemented, which successively links multiple single omics LUCID models using the Early Integration LUCID model. Let \\(G\\) be a \\(N \\times P\\) matrix with columns representing genetic/environmental exposures, and rows representing the observations; there is an ordered collection of \\(m\\) omics data, denoted by \\(Z_1\\), . . . , \\(Z_a\\), . . . , \\(Z_m\\) with corresponding dimensions \\(p_1\\), . . . , \\(p_a\\), . . . , \\(p_m\\). Successive omics layers \\(Z_a\\) are linked by using each observations’ posterior inclusion probability (PIP) for latent clusters \\(X_a\\) in the initial LUCID model to be the “exposure” variable for each successive model. The omics layers are ordered in a sequential fashion based on the biological relationships between omics layers. For the first model, an unsupervised Early Integration LUCID model using \\(G\\) as the exposure and \\(Z_1\\) as the omics layer. The PIPs of the non-reference clusters were extracted and used as the input for the exposure for the following unsupervised Early Integration LUCID model. This procedure is iterated until the last omics layer \\(Z_m\\), for which a supervised Early Integration LUCID model is used to conduct integrated clustering while using PIPs from the previous LUCID model and information on the outcome \\(Y\\).\nWhen using estimate_lucid() to fit LUCID in serial model, we specify lucid_model = \"serial\", and K is a list with the same length as the number of ordered omics layers and each element in the list is an integer representing number of latent clusters for the corresponding omics layer. G, Z, Y are the inputs for exposure, omics data matrix, and the outcome, respectively. Note that here Z is list of omics layers (vectors). CoY are the covariates to be adjusted for the \\(X\\) to \\(Y\\) association and CoG are the covariates to be adjusted for the \\(G\\) to \\(X\\) association. We specify useY = TRUE to construct supervised LUCID in serial model. We specify family = \"normal\" since the outcome is continuous. If the outcome is binary, we would specify family = \"binary\". We specify Rho_Z_Mu = 10 and Rho_Z_Cov = .3 to use LASSO penalty to regularize cluster-specific means and variance for \\(Z\\). We will get a selection of \\(Z\\) features for each layer, and then we refit the LUCID in serial model with only selected \\(Z\\) features to construct the final model.\n\n\nCode\nset.seed(100)\nG_Hg = exposure %&gt;% as.matrix()\nZ = list(omics_lst$methylome,\n         omics_lst$transcriptome,\n         omics_lst$miRNA)\nY_liv_inj = scale(outcome)\n\n#get the selection  \nfit &lt;- estimate_lucid(lucid_model = \"serial\",\n                      G = G_Hg,\n                      Z = Z,\n                      Y = Y_liv_inj, \n                      CoY = covs,\n                      CoG = covs,\n                      K = list(2,2,2),\n                      useY = TRUE,\n                      family = \"normal\", \n                      Rho_Z_Mu = 10,\n                      Rho_Z_Cov = .3)\n## Fitting LUCID in Serial model (Sub Model Number = 1) \n## Initialize LUCID with mclust \n## Fitting Early Integration LUCID model (K = 2, Rho_G = 0, Rho_Z_Mu = 10, Rho_Z_Cov = 0.3) \n## ...................Success: Early Integration LUCID converges! \n## \n## Fitting LUCID in Serial model (Sub Model Number = 2) \n## Initialize LUCID with mclust \n## Fitting Early Integration LUCID model (K = 2, Rho_G = 0, Rho_Z_Mu = 10, Rho_Z_Cov = 0.3) \n## ....................................................................................................................................................................................................................................Success: Early Integration LUCID converges! \n## \n## Fitting LUCID in Serial model (Sub Model Number = 3) \n## Initialize LUCID with mclust \n## Fitting Early Integration LUCID model (K = 2, Rho_G = 0, Rho_Z_Mu = 10, Rho_Z_Cov = 0.3) \n## ................................................Success: Early Integration LUCID converges! \n## \n## Success: LUCID in Serial Model is constructed!\n\n#extract selected Z features to to refit lUCID in serial\nselected_Z = vector(mode = \"list\", length = length(Z))\nfor (i in (1:length(Z))){\n  fiti_select_Z = fit$submodel[[i]]$select$selectZ\n  selected_Z[[i]] = Z[[i]][,fiti_select_Z]\n}\n\n#Refit ther LUCID in serial model with selected Z\nfit &lt;- estimate_lucid(lucid_model = \"serial\",\n                      G = G_Hg,\n                      Z = selected_Z,\n                      Y = Y_liv_inj, \n                      CoY = covs,\n                      CoG = covs,\n                      K = list(2,2,2),\n                      useY = TRUE,\n                      init_par = \"random\",\n                      family = \"normal\")\n## Fitting LUCID in Serial model (Sub Model Number = 1) \n## Initialize LUCID with random values from uniform distribution \n## Fitting Early Integration LUCID model (K = 2, Rho_G = 0, Rho_Z_Mu = 0, Rho_Z_Cov = 0) \n## .........................................Success: Early Integration LUCID converges! \n## \n## Fitting LUCID in Serial model (Sub Model Number = 2) \n## Initialize LUCID with random values from uniform distribution \n## Fitting Early Integration LUCID model (K = 2, Rho_G = 0, Rho_Z_Mu = 0, Rho_Z_Cov = 0) \n## ...........................................................................................Success: Early Integration LUCID converges! \n## \n## Fitting LUCID in Serial model (Sub Model Number = 3) \n## Initialize LUCID with random values from uniform distribution \n## Fitting Early Integration LUCID model (K = 2, Rho_G = 0, Rho_Z_Mu = 0, Rho_Z_Cov = 0) \n## .................................................................................................................................Success: Early Integration LUCID converges! \n## \n## Success: LUCID in Serial Model is constructed!\n\n# Rename Exposure\nfit1 &lt;- fit$submodel[[1]]\nfit1$var.names$Gnames[1] &lt;- \"Hg\"\nfit2 &lt;- fit$submodel[[2]]\nfit2$var.names$Gnames[1] &lt;- \"&lt;b&gt;Methylation\\nProfile 1&lt;/b&gt;\"\nfit3 &lt;- fit$submodel[[3]]\nfit3$var.names$Gnames[1] &lt;- \"&lt;b&gt;miRNA\\nProfile 1&lt;/b&gt;\"\n\n\n\n4.3.1 Sankey Diagram\nThe full code for the sankey_in_serial function is provided in Section 6.3.3\n\n\nCode\ncol_pal &lt;- RColorBrewer::brewer.pal(n = 8, name = \"Dark2\")\ncolor_pal_sankey &lt;- matrix(c(\"exposure\", \"red\",\n                             \"lc\",       \"#b3d8ff\",\n                             \"TC\",      col_pal[2],\n                             \"CpG\",       col_pal[1],\n                             \"miRNA\",  col_pal[3],\n                             \"outcome\",  \"grey\"), \n                           ncol = 2, byrow = TRUE) %&gt;%\n  as_tibble(.name_repair = \"unique\") %&gt;% \n  janitor::clean_names() %&gt;%\n  dplyr::rename(group = x1, color = x2)\n\np3&lt;- sankey_in_serial(fit1, \n                 fit2, \n                 fit3, \n                 color_pal_sankey,\n                 text_size = 24)\n\n\n\n\n\nFigure 4.3: The Sankey Diagram for LUCID in Serial (Late Integration)."
  },
  {
    "objectID": "software.html#r-packages",
    "href": "software.html#r-packages",
    "title": "5  Software",
    "section": "5.1 R packages",
    "text": "5.1 R packages\n\n\n\n\n\nList of all R Packages used in this book.\n\n\nPackage\nVersion\nAttached or Loaded\nDate/Publication\nSource\n\n\n\n\nboot\n1.3-28.1\nAttached\n2022-11-22\nCRAN (R 4.3.1)\n\n\nComplexHeatmap\n2.16.0\nAttached\n2023-05-08\nBioconductor\n\n\ncowplot\n1.1.1\nAttached\n2020-12-30\nCRAN (R 4.3.0)\n\n\ndevtools\n2.4.5\nAttached\n2022-10-11\nCRAN (R 4.3.0)\n\n\ndplyr\n1.1.3\nAttached\n2023-09-03\nCRAN (R 4.3.0)\n\n\ne1071\n1.7-13\nAttached\n2023-02-01\nCRAN (R 4.3.0)\n\n\nforcats\n1.0.0\nAttached\n2023-01-29\nCRAN (R 4.3.0)\n\n\nggh4x\n0.2.6\nAttached\n2023-08-30\nCRAN (R 4.3.0)\n\n\nggplot2\n3.4.4\nAttached\n2023-10-12\nCRAN (R 4.3.1)\n\n\nglasso\n1.11\nAttached\n2019-10-01\nCRAN (R 4.3.0)\n\n\nglmnet\n4.1-8\nAttached\n2023-08-22\nCRAN (R 4.3.0)\n\n\nHIMA\n2.2.1\nAttached\n2023-09-10\nCRAN (R 4.3.0)\n\n\nhtmlwidgets\n1.6.2\nAttached\n2023-03-17\nCRAN (R 4.3.0)\n\n\njsonlite\n1.8.7\nAttached\n2023-06-29\nCRAN (R 4.3.0)\n\n\nlavaan\n0.6-16\nAttached\n2023-07-19\nCRAN (R 4.3.0)\n\n\nlubridate\n1.9.3\nAttached\n2023-09-27\nCRAN (R 4.3.1)\n\n\nLUCIDus\n2.2.1\nAttached\n2022-11-08\nCRAN (R 4.3.0)\n\n\nMASS\n7.3-60\nAttached\n2023-05-04\nCRAN (R 4.3.1)\n\n\nMatrix\n1.6-1.1\nAttached\n2023-09-18\nCRAN (R 4.3.1)\n\n\nmclust\n6.0.0\nAttached\n2022-10-31\nCRAN (R 4.3.0)\n\n\nncvreg\n3.14.1\nAttached\n2023-04-25\nCRAN (R 4.3.0)\n\n\nnetworkD3\n0.4\nAttached\n2017-03-18\nCRAN (R 4.3.0)\n\n\nnnet\n7.3-19\nAttached\n2023-05-03\nCRAN (R 4.3.1)\n\n\nOpenMx\n2.21.8\nAttached\n2023-04-05\nCRAN (R 4.3.0)\n\n\nplotly\n4.10.2\nAttached\n2023-06-03\nCRAN (R 4.3.0)\n\n\nprogress\n1.2.2\nAttached\n2019-05-16\nCRAN (R 4.3.0)\n\n\npurrr\n1.0.2\nAttached\n2023-08-10\nCRAN (R 4.3.0)\n\n\nr.jive\n2.4\nAttached\n2020-11-17\nCRAN (R 4.3.0)\n\n\nreadr\n2.1.4\nAttached\n2023-02-10\nCRAN (R 4.3.0)\n\n\nRMediation\n1.2.2\nAttached\n2023-05-12\nCRAN (R 4.3.0)\n\n\nstringr\n1.5.0\nAttached\n2022-12-02\nCRAN (R 4.3.0)\n\n\ntable1\n1.4.3\nAttached\n2023-01-06\nCRAN (R 4.3.0)\n\n\ntibble\n3.2.1\nAttached\n2023-03-20\nCRAN (R 4.3.0)\n\n\ntidyr\n1.3.0\nAttached\n2023-01-24\nCRAN (R 4.3.0)\n\n\ntidyverse\n2.0.0\nAttached\n2023-02-22\nCRAN (R 4.3.0)\n\n\nusethis\n2.2.2\nAttached\n2023-07-06\nCRAN (R 4.3.0)\n\n\nxtune\n2.0.0\nAttached\n2023-06-18\nCRAN (R 4.3.0)\n\n\nabind\n1.4-5\nLoaded\n2016-07-21\nCRAN (R 4.3.0)\n\n\nadaptMCMC\n1.4\nLoaded\n2021-03-29\nCRAN (R 4.3.0)\n\n\nbackports\n1.4.1\nLoaded\n2021-12-13\nCRAN (R 4.3.0)\n\n\nBiocGenerics\n0.46.0\nLoaded\n2023-06-04\nBioconductor\n\n\nbitops\n1.0-7\nLoaded\n2021-04-24\nCRAN (R 4.3.0)\n\n\nbroom\n1.0.5\nLoaded\n2023-06-09\nCRAN (R 4.3.0)\n\n\ncachem\n1.0.8\nLoaded\n2023-05-01\nCRAN (R 4.3.0)\n\n\ncallr\n3.7.3\nLoaded\n2022-11-02\nCRAN (R 4.3.0)\n\n\ncaTools\n1.18.2\nLoaded\n2021-03-28\nCRAN (R 4.3.0)\n\n\ncirclize\n0.4.15\nLoaded\n2022-05-10\nCRAN (R 4.3.0)\n\n\nclass\n7.3-22\nLoaded\n2023-05-03\nCRAN (R 4.3.1)\n\n\ncli\n3.6.1\nLoaded\n2023-03-23\nCRAN (R 4.3.0)\n\n\nclue\n0.3-65\nLoaded\n2023-09-23\nCRAN (R 4.3.1)\n\n\ncluster\n2.1.4\nLoaded\n2022-08-22\nCRAN (R 4.3.1)\n\n\ncoda\n0.19-4\nLoaded\n2020-09-30\nCRAN (R 4.3.0)\n\n\ncodetools\n0.2-19\nLoaded\n2023-02-01\nCRAN (R 4.3.1)\n\n\ncolorspace\n2.1-0\nLoaded\n2023-01-23\nCRAN (R 4.3.0)\n\n\nconquer\n1.3.3\nLoaded\n2023-03-06\nCRAN (R 4.3.0)\n\n\ncrayon\n1.5.2\nLoaded\n2022-09-29\nCRAN (R 4.3.0)\n\n\ndata.table\n1.14.8\nLoaded\n2023-02-17\nCRAN (R 4.3.0)\n\n\ndigest\n0.6.33\nLoaded\n2023-07-07\nCRAN (R 4.3.0)\n\n\ndoParallel\n1.0.17\nLoaded\n2022-02-07\nCRAN (R 4.3.0)\n\n\nellipsis\n0.3.2\nLoaded\n2021-04-29\nCRAN (R 4.3.0)\n\n\nevaluate\n0.22\nLoaded\n2023-09-29\nCRAN (R 4.3.1)\n\n\nfansi\n1.0.5\nLoaded\n2023-10-08\nCRAN (R 4.3.1)\n\n\nfastmap\n1.1.1\nLoaded\n2023-02-24\nCRAN (R 4.3.0)\n\n\nfdrtool\n1.2.17\nLoaded\n2021-11-13\nCRAN (R 4.3.0)\n\n\nforeach\n1.5.2\nLoaded\n2022-02-02\nCRAN (R 4.3.0)\n\n\nFormula\n1.2-5\nLoaded\n2023-02-24\nCRAN (R 4.3.0)\n\n\nfs\n1.6.3\nLoaded\n2023-07-20\nCRAN (R 4.3.0)\n\n\ngenerics\n0.1.3\nLoaded\n2022-07-05\nCRAN (R 4.3.0)\n\n\nGetoptLong\n1.0.5\nLoaded\n2020-12-15\nCRAN (R 4.3.0)\n\n\nGlobalOptions\n0.1.2\nLoaded\n2020-06-10\nCRAN (R 4.3.0)\n\n\nglue\n1.6.2\nLoaded\n2022-02-24\nCRAN (R 4.3.0)\n\n\ngplots\n3.1.3\nLoaded\n2022-04-25\nCRAN (R 4.3.0)\n\n\ngtable\n0.3.4\nLoaded\n2023-08-21\nCRAN (R 4.3.0)\n\n\ngtools\n3.9.4\nLoaded\n2022-11-27\nCRAN (R 4.3.0)\n\n\nhdi\n0.1-9\nLoaded\n2021-05-27\nCRAN (R 4.3.0)\n\n\nHDMT\n1.0.5\nLoaded\n2022-01-29\nCRAN (R 4.3.0)\n\n\nhere\n1.0.1\nLoaded\n2020-12-13\nCRAN (R 4.3.0)\n\n\nhms\n1.1.3\nLoaded\n2023-03-21\nCRAN (R 4.3.0)\n\n\nhommel\n1.6\nLoaded\n2021-12-17\nCRAN (R 4.3.0)\n\n\nhtmltools\n0.5.6.1\nLoaded\n2023-10-06\nCRAN (R 4.3.1)\n\n\nhttpuv\n1.6.11\nLoaded\n2023-05-11\nCRAN (R 4.3.0)\n\n\nhttr\n1.4.7\nLoaded\n2023-08-15\nCRAN (R 4.3.0)\n\n\nigraph\n1.5.1\nLoaded\n2023-08-10\nCRAN (R 4.3.0)\n\n\nintervals\n0.15.4\nLoaded\n2023-06-29\nCRAN (R 4.3.0)\n\n\nIRanges\n2.34.1\nLoaded\n2023-07-02\nBioconductor\n\n\niterators\n1.0.14\nLoaded\n2022-02-05\nCRAN (R 4.3.0)\n\n\nKernSmooth\n2.23-22\nLoaded\n2023-07-10\nCRAN (R 4.3.0)\n\n\nknitr\n1.44\nLoaded\n2023-09-11\nCRAN (R 4.3.0)\n\n\nlars\n1.3\nLoaded\n2022-04-13\nCRAN (R 4.3.0)\n\n\nlater\n1.3.1\nLoaded\n2023-05-02\nCRAN (R 4.3.0)\n\n\nlattice\n0.21-9\nLoaded\n2023-10-01\nCRAN (R 4.3.1)\n\n\nlazyeval\n0.2.2\nLoaded\n2019-03-15\nCRAN (R 4.3.0)\n\n\nlbfgs\n1.2.1.2\nLoaded\n2022-06-23\nCRAN (R 4.3.0)\n\n\nlifecycle\n1.0.3\nLoaded\n2022-10-07\nCRAN (R 4.3.0)\n\n\nlinprog\n0.9-4\nLoaded\n2022-03-09\nCRAN (R 4.3.0)\n\n\nlpSolve\n5.6.19\nLoaded\n2023-09-13\nCRAN (R 4.3.0)\n\n\nmagrittr\n2.0.3\nLoaded\n2022-03-30\nCRAN (R 4.3.0)\n\n\nMatrixModels\n0.5-2\nLoaded\n2023-07-10\nCRAN (R 4.3.0)\n\n\nmatrixStats\n1.0.0\nLoaded\n2023-06-02\nCRAN (R 4.3.0)\n\n\nmemoise\n2.0.1\nLoaded\n2021-11-26\nCRAN (R 4.3.0)\n\n\nmime\n0.12\nLoaded\n2021-09-28\nCRAN (R 4.3.0)\n\n\nminiUI\n0.1.1.1\nLoaded\n2018-05-18\nCRAN (R 4.3.0)\n\n\nmix\n1.0-11\nLoaded\n2022-05-31\nCRAN (R 4.3.0)\n\n\nmnormt\n2.1.1\nLoaded\n2022-09-26\nCRAN (R 4.3.0)\n\n\nmodelr\n0.1.11\nLoaded\n2023-03-22\nCRAN (R 4.3.0)\n\n\nmunsell\n0.5.0\nLoaded\n2018-06-12\nCRAN (R 4.3.0)\n\n\npbivnorm\n0.6.0\nLoaded\n2015-01-23\nCRAN (R 4.3.0)\n\n\npillar\n1.9.0\nLoaded\n2023-03-22\nCRAN (R 4.3.0)\n\n\npkgbuild\n1.4.2\nLoaded\n2023-06-26\nCRAN (R 4.3.0)\n\n\npkgconfig\n2.0.3\nLoaded\n2019-09-22\nCRAN (R 4.3.0)\n\n\npkgload\n1.3.3\nLoaded\n2023-09-22\nCRAN (R 4.3.1)\n\n\nplyr\n1.8.9\nLoaded\n2023-10-02\nCRAN (R 4.3.1)\n\n\npng\n0.1-8\nLoaded\n2022-11-29\nCRAN (R 4.3.0)\n\n\nprettyunits\n1.2.0\nLoaded\n2023-09-24\nCRAN (R 4.3.1)\n\n\nprocessx\n3.8.2\nLoaded\n2023-06-30\nCRAN (R 4.3.0)\n\n\nprofvis\n0.3.8\nLoaded\n2023-05-02\nCRAN (R 4.3.0)\n\n\npromises\n1.2.1\nLoaded\n2023-08-10\nCRAN (R 4.3.0)\n\n\nproxy\n0.4-27\nLoaded\n2022-06-09\nCRAN (R 4.3.0)\n\n\nps\n1.7.5\nLoaded\n2023-04-18\nCRAN (R 4.3.0)\n\n\nquadprog\n1.5-8\nLoaded\n2019-11-20\nCRAN (R 4.3.0)\n\n\nquantreg\n5.97\nLoaded\n2023-08-19\nCRAN (R 4.3.0)\n\n\nqvalue\n2.32.0\nLoaded\n2023-05-08\nBioconductor\n\n\nR6\n2.5.1\nLoaded\n2021-08-19\nCRAN (R 4.3.0)\n\n\nRColorBrewer\n1.1-3\nLoaded\n2022-04-03\nCRAN (R 4.3.0)\n\n\nRcpp\n1.0.11\nLoaded\n2023-07-06\nCRAN (R 4.3.0)\n\n\nRcppParallel\n5.1.7\nLoaded\n2023-02-27\nCRAN (R 4.3.0)\n\n\nremotes\n2.4.2.1\nLoaded\n2023-07-18\nCRAN (R 4.3.0)\n\n\nreshape2\n1.4.4\nLoaded\n2020-04-09\nCRAN (R 4.3.0)\n\n\nrjson\n0.2.21\nLoaded\n2022-01-09\nCRAN (R 4.3.0)\n\n\nrlang\n1.1.1\nLoaded\n2023-04-28\nCRAN (R 4.3.0)\n\n\nrmarkdown\n2.25\nLoaded\n2023-09-18\nCRAN (R 4.3.1)\n\n\nrprojroot\n2.0.3\nLoaded\n2022-04-02\nCRAN (R 4.3.0)\n\n\nrstudioapi\n0.15.0\nLoaded\n2023-07-07\nCRAN (R 4.3.0)\n\n\nS4Vectors\n0.38.2\nLoaded\n2023-09-24\nBioconductor\n\n\nscales\n1.2.1\nLoaded\n2022-08-20\nCRAN (R 4.3.0)\n\n\nscalreg\n1.0.1\nLoaded\n2019-01-25\nCRAN (R 4.3.0)\n\n\nselectiveInference\n1.2.5\nLoaded\n2019-09-07\nCRAN (R 4.3.0)\n\n\nsessioninfo\n1.2.2\nLoaded\n2021-12-06\nCRAN (R 4.3.0)\n\n\nshape\n1.4.6\nLoaded\n2021-05-19\nCRAN (R 4.3.0)\n\n\nshiny\n1.7.5.1\nLoaded\n2023-10-14\nCRAN (R 4.3.1)\n\n\nSparseM\n1.81\nLoaded\n2021-02-18\nCRAN (R 4.3.0)\n\n\nstringi\n1.7.12\nLoaded\n2023-01-11\nCRAN (R 4.3.0)\n\n\nsurvival\n3.5-7\nLoaded\n2023-08-14\nCRAN (R 4.3.0)\n\n\ntidyselect\n1.2.0\nLoaded\n2022-10-10\nCRAN (R 4.3.0)\n\n\ntimechange\n0.2.0\nLoaded\n2023-01-11\nCRAN (R 4.3.0)\n\n\ntzdb\n0.4.0\nLoaded\n2023-05-12\nCRAN (R 4.3.0)\n\n\nurlchecker\n1.0.1\nLoaded\n2021-11-30\nCRAN (R 4.3.0)\n\n\nutf8\n1.2.3\nLoaded\n2023-01-31\nCRAN (R 4.3.0)\n\n\nvctrs\n0.6.4\nLoaded\n2023-10-12\nCRAN (R 4.3.1)\n\n\nviridisLite\n0.4.2\nLoaded\n2023-05-02\nCRAN (R 4.3.0)\n\n\nwithr\n2.5.1\nLoaded\n2023-09-26\nCRAN (R 4.3.1)\n\n\nxfun\n0.40\nLoaded\n2023-08-09\nCRAN (R 4.3.0)\n\n\nxtable\n1.8-4\nLoaded\n2019-04-21\nCRAN (R 4.3.0)"
  },
  {
    "objectID": "software.html#software-environment",
    "href": "software.html#software-environment",
    "title": "5  Software",
    "section": "5.2 Software Environment",
    "text": "5.2 Software Environment\nThis book was developed on the following platform.\n\n\n\n\n\n\n\nSetting\nValue\n\n\n\n\nversion\nR version 4.3.1 (2023-06-16)\n\n\nos\nmacOS Sonoma 14.0\n\n\nsystem\naarch64, darwin20\n\n\nui\nX11\n\n\nlanguage\n(EN)\n\n\ncollate\nen_US.UTF-8\n\n\nctype\nen_US.UTF-8\n\n\ntz\nAmerica/Los_Angeles\n\n\ndate\n2023-10-16\n\n\npandoc\n3.1.1 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)"
  },
  {
    "objectID": "appendix_code.html#high-dimensional-mediation-analysis-code",
    "href": "appendix_code.html#high-dimensional-mediation-analysis-code",
    "title": "6  Supplemental Code",
    "section": "6.1 High Dimensional Mediation Analysis Code",
    "text": "6.1 High Dimensional Mediation Analysis Code\n\n6.1.1 Early Integration of omics datasets\n\n\nCode\n#' Conducts High Dimensional Mediation Analysis with Early Integration\n#' \n#' Given exposure, outcome and multiple omics data,\n#' function runs HIMA mediation analysis with early integration\n#' and returns a tidy dataframe for the results\n#'\n#' @param exposure A numeric vector for the exposure variable\n#' @param outcome A numeric vector for the outcome variable\n#' @param omics A list of numeric matrices representing omics data\n#' @param covs A numeric matrix representing the covariates\n#'\n#' @return A tidy dataframe summarizing the results of HIMA analysis\n#'\n#' @import dplyr\n#' @importFrom tidyr as_tibble\n#' @importFrom dplyr left_join\n#' @importFrom janitor remove_empty\n#' @importFrom purrr map_lgl\n#' @importFrom stringr str_detect\n#' @importFrom stats gaussian\n#' @importFrom HIMA hima\n#' @importFrom base as.matrix\nhima_early_integration &lt;- function(exposure, \n                                   outcome, \n                                   omics_lst, \n                                   covs, \n                                   Y.family = \"binomial\",\n                                   M.family = \"gaussian\") {\n  # Give error if covs is NULL\n  if (is.null(covs)) {\n    stop(\"Currently, hima does not support analysis without covariates.\n         Please provide covariates.\")\n  }\n  \n  # Combines omics data into one dataframe\n  omics_lst_df &lt;- purrr::map(omics_lst, ~as_tibble(.x, rownames = \"name\"))\n  \n  meta_df &lt;- imap_dfr(omics_lst_df, ~tibble(omic_layer = .y, ftr_name = names(.x)))%&gt;%\n    filter(ftr_name != \"name\") %&gt;%\n    mutate(omic_num = case_when(str_detect(omic_layer, \"meth\") ~ 1, \n                                str_detect(omic_layer, \"transc\") ~ 2, \n                                str_detect(omic_layer, \"miR\") ~ 3,\n                                str_detect(omic_layer, \"pro\") ~ 4, \n                                str_detect(omic_layer, \"met\") ~ 5))\n  \n  # Create data frame of omics data\n  omics_df &lt;- omics_lst_df  %&gt;% \n    purrr::reduce(left_join, by = \"name\") %&gt;%\n    column_to_rownames(\"name\")\n  \n  # Run hima\n  result_hima_early &lt;- hima(X = exposure,\n                            Y = outcome,\n                            M = omics_df,\n                            COV.XM = covs,\n                            COV.MY = covs,\n                            Y.family = Y.family,\n                            M.family = M.family,\n                            verbose = FALSE, \n                            max.iter = 100000, \n                            scale = FALSE) %&gt;%\n    as_tibble(rownames = \"ftr_name\")\n  \n  # Reorders the columns and adds the omics layer information\n  result_hima_early &lt;- result_hima_early %&gt;%\n    dplyr::mutate(\n      multiomic_mthd = \"Early Integration\",\n      mediation_mthd = \"HIMA\") %&gt;%\n    dplyr::select(multiomic_mthd, mediation_mthd, \n                  ftr_name, \n                  everything())\n  # Filter to significant features only and scale % total effect to 100\n  result_hima_early &lt;- result_hima_early %&gt;% \n    filter(BH.FDR &lt; 0.05) %&gt;%\n    mutate(pte = 100*`% total effect`/sum(`% total effect`), \n           sig = if_else(BH.FDR &lt; 0.05, 1, 0)) %&gt;%\n    rename(ie = 'alpha*beta', \n           `TE (%)` = pte)\n  \n  # Merge results with feature metadata \n  result_hima_early &lt;- result_hima_early %&gt;% \n    left_join(meta_df, by = \"ftr_name\")\n  \n  # Return result\n  return(result_hima_early)\n}\n\n\n\n\n6.1.2 Intermediate Integration of omics datasets\n\n\nCode\n#' Conducts High Dimensional Mediation Analysis with Intermediate Integration\n#' Combines -omic data with covariates to calculate the indirect effect \n#' of each individial, possible mediating feature on the relationship\n#' between exposure and outcome using cooperative group lasso \n#'\n#' @param omics list of dataframes with -omic data\n#' @param covs dataframe with covariate data\n#' @param outcome vector with outcome variable data\n#' @param exposure vector with exposure variable data\n#' @param n_boot number indicating number of bootstrap estimates to perform for se\n#'\n#' @return dataframe with the following variables: ftr_name, omic_layer, \n#' alpha, alpha_se, s1, beta_bootstrap, beta_se, indirect, ind_effect_se, \n#' lcl, ucl, gamma, pte_intermediate, sig_intermediate\n#' \n#' @examples\n#' calculate_mediation(omics = list(omics_1, omics_2),\n#'                     covs = covariate_data, \n#'                     outcome = outcome_data, \n#'                     exposure = exposure_data. \n#'                     n_boot = 100)\n#' \n#' @importFrom epiomics owas\n#' @importFrom dplyr bind_cols group_by inner_join mutate \n#' @importFrom dplyr select rename filter summarise \n#' @importFrom purrr map map2 reduce \n#' @importFrom broom tidy \n#' @importFrom matrixStats colAnyNA rowAnyNA \n#' @importFrom RMediation medci\n#' @importFrom boot boot detectCores\n#' @importFrom glmnet::groupedlasso grouped.lasso::groupedlasso\n#' @importFrom glmnet::cv.groupedlasso cv.groupedlasso::cv.groupedlasso\n#' @importFrom glmnet::cvglmnet cvglmnet::cvglmnet\n#' @importFrom glmnet::predict.cv.glmnet predict.cv.glmnet\n#' @importFrom matrixStats colAlls rowSds rowMeans\n#' @importFrom stringr str_detect\nhima_intermediate_integration &lt;- function(exposure, \n                                          outcome, \n                                          omics_lst,   \n                                          covs = NULL, \n                                          n_boot, \n                                          Y.family = \"gaussian\") {\n  ## Change omics elements to dataframes \n  omics_lst_df &lt;- purrr::map(omics_lst, ~as_tibble(.x, rownames = \"name\"))\n  \n  meta_df &lt;- imap_dfr(omics_lst_df, ~tibble(omic_layer = .y, ftr_name = names(.x)))%&gt;%\n    filter(ftr_name != \"name\") %&gt;%\n    mutate(omic_num = case_when(str_detect(omic_layer, \"meth\") ~ 1, \n                                str_detect(omic_layer, \"transc\") ~ 2, \n                                str_detect(omic_layer, \"miR\") ~ 3,\n                                str_detect(omic_layer, \"pro\") ~ 4, \n                                str_detect(omic_layer, \"met\") ~ 5))\n  \n  ## Create data frame of omics data\n  omics_df &lt;- omics_lst_df  %&gt;% \n    purrr::reduce(left_join, by = \"name\") %&gt;%\n    column_to_rownames(\"name\")\n  \n  # Rename family for xtune function\n  if(Y.family != \"gaussian\") {stop(\"Only continuous outcomes currently supported\")}\n  \n  # Get dataframe of all data\n  full_data &lt;- tibble(outcome = outcome, \n                      exposure = exposure) %&gt;% \n    bind_cols(omics_df)\n  \n  # Add covs if not null\n  if(!is.null(covs)) {full_data &lt;- full_data %&gt;% bind_cols(covs)}\n  \n  # Get external information matrix\n  # Convert each data frame to a long format and extract the unique column names\n  external_info &lt;- purrr::map(omics_lst, \n                              ~data.frame(column = colnames(.x), val = 1)) %&gt;%\n    map2(names(omics_lst), ~dplyr::rename(.x, !!.y := val)) %&gt;%\n    purrr::reduce(., full_join, by = \"column\") %&gt;%\n    replace(is.na(.), 0) %&gt;%\n    column_to_rownames(\"column\")\n  \n  # 0) calculate gamma (x --&gt; y) ----\n  if(Y.family == \"binary\"){\n    gamma_est &lt;- coef(glm(outcome ~ exposure + as.matrix(covs), \n                          family = binomial))[[\"exposure\"]]  \n  } else if(Y.family == \"gaussian\"){ \n    gamma_est &lt;- coef(lm(outcome ~ exposure ))[[\"exposure\"]]  \n  }\n   \n  # 1) X --&gt; M ----------\n  # Model 1: x --&gt; m\n  x_m_reg &lt;- epiomics::owas(df = full_data,\n                            omics = rownames(external_info),\n                            covars = colnames(covs),\n                            var = \"exposure\",\n                            var_exposure_or_outcome = \"exposure\") %&gt;%\n    dplyr::select(feature_name, estimate, se) %&gt;%\n    dplyr::rename(alpha = estimate, \n                  alpha_se = se)\n  \n  # 2) M--&gt; Y: select features associated with the outcome using group lasso ----\n  # x+M--&gt;Y Glasso\n  X = as.matrix(full_data[, colnames(omics_df)])\n  Y = full_data$outcome\n  Z = as.matrix(external_info)\n  U = as.matrix(full_data[,\"exposure\"])\n  if(is.null(covs)){ \n    U = as.matrix(full_data[,\"exposure\"])\n  } else { \n    U = as.matrix(full_data[,c(colnames(covs), \"exposure\")])  \n  }\n  \n  # Run xtune\n  invisible(\n    capture.output(\n      xtune.fit_all_data &lt;- xtune(X = X, Y = Y, Z = Z, U = U,\n                                  c = 1, \n                                  family = \"linear\")\n    )\n  )\n  \n  # Extract estimates\n  xtune_betas_all_data &lt;- as_tibble(as.matrix(xtune.fit_all_data$beta.est),\n                                    rownames = \"feature_name\") %&gt;% \n    left_join(meta_df, by = c(\"feature_name\" = \"ftr_name\")) %&gt;%\n    dplyr::filter(feature_name %in% colnames(omics_df))\n  \n  # 3) Calculate SE for Model 3: x+m to y reg -----\n  # 3.1) boot function --------------------------------------------------------\n  group_lasso_boot &lt;- function(data, indices, external_info, covs = NULL) {\n    X = as.matrix(data)[indices, rownames(external_info)]\n    Y = data$outcome[indices]\n    if(is.null(covs)){\n      U = as.matrix(data[indices,\"exposure\"])\n    } else {\n      U = as.matrix(data[indices,c(colnames(covs), \"exposure\")])\n    }\n    # Run xtune with error catching function, sometimes xtune needs to run again\n    success &lt;- FALSE\n    attempts &lt;- 0\n    while(!success & attempts &lt; 10) {\n      tryCatch({\n        # Run xtune\n        xtune.fit &lt;- xtune(X = X, Y = Y, Z = as.matrix(external_info), U = U,\n                           sigma.square = estimateVariance(X,Y), \n                           c = 0, \n                           family = \"linear\", message = FALSE)\n        \n        \n        # If the xtune call is successful, proceed with the rest of the code\n        # Select betas, drop intercept\n        xtune_betas &lt;- as_tibble(as.matrix(xtune.fit$beta.est),\n                                 rownames = \"feature_name\") %&gt;% \n          dplyr::filter(feature_name %in% colnames(omics_df)) %&gt;%\n          dplyr::select(s1) %&gt;%\n          as.matrix()\n        # Fix issue where sometimes lasso returns a null matrix\n        if(sum(dim(xtune_betas) == c(nrow(external_info), 1))==2){\n          return(xtune_betas)\n        } else {\n          return(as.matrix(rep(0, nrow(external_info))))\n        }\n        \n        success &lt;- TRUE\n      }, error = function(e) {\n        attempts &lt;- attempts + 1\n        print(paste0(\"Encountered error: \", e$message))\n        if (attempts &lt; 10) {\n          print(\"Retrying...\")\n        } else {\n          print(\"Maximum number of attempts reached. Exiting...\")\n          return(NULL)\n        }\n      })\n    }\n  }\n  \n  \n  # 3.2) Run Bootstrap analysis ----------------------\n  # Run Bootstrap\n  if(is.null(covs)){ \n    boot_out &lt;- boot(data = full_data,\n                     statistic = group_lasso_boot,\n                     R = n_boot,\n                     # strata = as.numeric(full_data$h_cohort),\n                     ncpus = detectCores(),\n                     parallel = \"multicore\", \n                     external_info = external_info)\n  } else {\n    boot_out &lt;- boot(data = full_data,\n                     statistic = group_lasso_boot,\n                     R = n_boot,\n                     # strata = as.numeric(full_data$h_cohort),\n                     ncpus = detectCores(),\n                     parallel = \"multicore\", \n                     external_info = external_info, \n                     covs = covs)\n  }\n  \n  \n  # Calculate percent of times feature was selected\n  glasso_boot_results &lt;- tibble(\n    feature_name = rownames(external_info), \n    beta_bootstrap = colMeans(replace_na(boot_out$t, 0)), \n    beta_se = apply(replace_na(boot_out$t, 0), 2, sd)) %&gt;%\n    left_join(meta_df, by = c(\"feature_name\" = \"ftr_name\"))\n  \n  # 3.4) Join unpenalized results with glasso results ----\n  int_med_coefs &lt;- dplyr::inner_join(xtune_betas_all_data, \n                                     glasso_boot_results, \n                                     by = c(\"feature_name\", \n                                            \"omic_layer\", \"omic_num\")) %&gt;% \n    dplyr::inner_join(x_m_reg, by = \"feature_name\")\n  \n  # Calculate confidence intervals -----\n  # mu.x: a1 from reg m = a0 + a1*X\n  # mu.y: b2 from reg y = b0 + b1*X + b2*M\n  int_med_res &lt;- int_med_coefs %&gt;%\n    group_by(feature_name) %&gt;% \n    nest() %&gt;%\n    mutate(res = purrr::map(data, \n                            ~RMediation::medci(mu.x = .x$alpha, \n                                               se.x = .x$alpha_se, \n                                               mu.y = .x$beta_bootstrap,\n                                               se.y = .x$beta_se,  \n                                               type = \"dop\") %&gt;% \n                              unlist() %&gt;% t() %&gt;% as_tibble())) %&gt;%\n    unnest(c(res, data)) %&gt;%\n    ungroup() %&gt;%\n    janitor::clean_names()\n  \n  # Modify results \n  intermediate_int_res &lt;- int_med_res %&gt;%\n    janitor::clean_names() %&gt;%\n    rename(indirect = \"estimate\", \n           ind_effect_se = \"se\", \n           lcl = x95_percent_ci1,\n           ucl = x95_percent_ci2) %&gt;% \n    mutate(gamma = gamma_est, \n           pte = (indirect)/gamma, \n           sig = if_else(lcl&gt;0|ucl&lt;0, 1, 0))\n  \n    # Filter to significant features only and scale % total effect to 100\n  intermediate_int_res &lt;- intermediate_int_res %&gt;% \n    filter(sig == 1) %&gt;%\n    mutate(pte = 100*pte/sum(pte))\n  \n  \n  # Rename feature name\n  intermediate_int_res &lt;- intermediate_int_res %&gt;% \n    dplyr::rename(ftr_name = feature_name,\n                  ie = indirect, \n                  beta = beta_bootstrap, \n                  `TE (%)` = pte)\n  \n  return(intermediate_int_res)\n}\n\n\n\n\n6.1.3 Late Integration of omics datasets\n\n\nCode\n#' Conducts High Dimensional Mediation Analysis with Late Integration\n#' Performs HIMA mediation analysis on multiple omics layers with late integration\n#'\n#' This function uses HIMA (High-dimensional Mediation Analysis) to perform \n#' mediation analyses on multiple omics layers. For each omics layer, it runs \n#' HIMA with exposure, outcome, covariates, and that specific omics layer as \n#' input, and then collects the results as a tibble. The results for each type\n#' of omics layer are stored in a list and then concatenated to form the final \n#' result. The values are scaled to a percentage of total effect and metadata \n#' is joined to fill in missing information.\n#'\n#' @param exposure a numeric vector containing exposure measurements\n#' @param outcome a numeric vector containing outcome measurements\n#' @param omics a named list containing multiple omics layers\n#' @param covs a data frame containing covariate information\n#' @param omics_names a data frame with metadata for each omics layer\n#' @return a tibble with High-dimensional Mediation Analysis results, including metadata\n#' @importFrom dplyr mutate select left_join across\n#' @importFrom janitor remove_empty\n#' @importFrom HIMA hima\n#' @importFrom purrr map\n#' @importFrom stats var\n#'\n#' @export\nhima_late_integration &lt;- function(exposure,\n                                  outcome,\n                                  omics_lst,\n                                  covs, \n                                  Y.family,\n                                  M.family = \"gaussian\") {\n  \n  # Give error if covs is NULL\n  if (is.null(covs)) {\n    stop(\"Currently, hima does not support analysis without covariates.\n         Please provide covariates.\")\n  }\n  \n  # Get number of omics layers\n  n_omics &lt;- length(omics_lst)\n  omics_name &lt;- names(omics_lst)\n  \n  # Meta data\n  omics_lst_df &lt;- purrr::map(omics_lst, ~as_tibble(.x, rownames = \"name\"))\n  \n  meta_df &lt;- imap_dfr(omics_lst_df, ~tibble(omic_layer = .y, ftr_name = names(.x)))%&gt;%\n    filter(ftr_name != \"name\") %&gt;%\n    mutate(omic_num = case_when(str_detect(omic_layer, \"meth\") ~ 1, \n                                str_detect(omic_layer, \"transc\") ~ 2, \n                                str_detect(omic_layer, \"miR\") ~ 3,\n                                str_detect(omic_layer, \"pro\") ~ 4, \n                                str_detect(omic_layer, \"met\") ~ 5))\n  # Start the computation\n  result_hima_late &lt;- vector(mode = \"list\", length = n_omics)\n  for(i in 1:n_omics) {\n    # Run HIMA with input data\n    result_hima_late[[i]] &lt;- hima(X = exposure,\n                                  Y = outcome,\n                                  M = omics_lst[[i]],\n                                  COV.XM = covs,\n                                  Y.family = Y.family,\n                                  M.family = M.family, \n                                  max.iter = 100000, \n                                  scale = FALSE) %&gt;%\n      as_tibble(rownames = \"ftr_name\")\n  }\n  \n  # Assign omic names\n  names(result_hima_late) &lt;- names(omics_lst)\n  \n  # Concatenate the resulting data frames\n  result_hima_late_df &lt;- bind_rows(result_hima_late, .id = \"omic_layer\")\n  \n  # Add key details\n  result_hima_late_df &lt;- result_hima_late_df %&gt;%\n    dplyr::mutate(\n      multiomic_mthd = \"Late Integration\",\n      mediation_mthd = \"HIMA\") %&gt;%\n    dplyr::select(multiomic_mthd, mediation_mthd, \n                  omic_layer, ftr_name, \n                  everything())\n  \n  # Filter to significant features only and scale % total effect to 100\n  result_hima_late_df &lt;- result_hima_late_df %&gt;% \n    filter(BH.FDR &lt; 0.05) %&gt;%\n    mutate(pte = 100*`% total effect`/sum(`% total effect`), \n           sig = if_else(BH.FDR &lt; 0.05, 1, 0)) %&gt;%\n    rename(ie = 'alpha*beta', \n           `TE (%)` = pte)\n  \n  # Return the final table\n  return(result_hima_late_df)\n}\n\n\n\n\n6.1.4 Plot HIMA\n\n\nCode\n#' Plot of High Dimensional Mediation Analysis\n#' \n#' Given a tidy dataframe summarizing the results of HIMA analysis\n#'\n#' @param result_hima  a tidy dataframe summarizing the results of HIMA analysis\n#'\n#' @return a figure of the result of HIMA analysis\n#'\n#' @import dplyr\n#' @importFrom ggplot2 ggplot\n#' \nplot_hima &lt;- function(result_hima) {\n  # Pivot longer for figure\n  result_hima_long &lt;- result_hima %&gt;% \n    rename(Alpha = alpha,\n           Beta = beta) %&gt;%\n    pivot_longer(cols = c(Alpha, Beta,`TE (%)`), \n                 names_to = \"name\") %&gt;%\n    mutate(name = factor(name, levels = c(\"Alpha\", \"Beta\", \"TE (%)\")))\n  \n  # Plot features\n  p &lt;- ggplot(result_hima_long, \n         aes(x = fct_inorder(ftr_name), \n             y = value,\n             fill = omic_layer)) + \n    geom_bar(stat = \"identity\") +\n    facet_grid(name ~ omic_layer, \n               scales = \"free\",\n               space = \"free_x\") +\n    scale_fill_brewer(type = \"qual\", palette = 2) +\n    geom_hline(yintercept = 0, linetype = 1, color = \"grey50\") + \n    ylab(NULL) + xlab(NULL) +\n    theme(\n      strip.background = element_blank(),\n      strip.text.x = element_blank(),\n      axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5),\n      legend.title = element_blank(), \n      legend.position = \"bottom\", # Place the legend at the bottom\n      legend.justification = c(1, 0))\n  \n  return(p)\n}"
  },
  {
    "objectID": "appendix_code.html#mediation-with-latent-factors-analysis-code",
    "href": "appendix_code.html#mediation-with-latent-factors-analysis-code",
    "title": "6  Supplemental Code",
    "section": "6.2 Mediation with Latent Factors Analysis Code",
    "text": "6.2 Mediation with Latent Factors Analysis Code\n\n6.2.1 Early Integration of omics datasets\n\n\nCode\n#' Conduct principal component analysis (PCA) as a dimensional reduction step \n#' and selected the top i principal components which explained &gt;80% of the variance. \n#' Following the joint dimensional reduction step, conduct mediation analysis.\n\n#' Given exposure, outcome and multiple omics data,\n#' function runs HIMA mediation analysis with latent factors in early integration\n#' and returns a list including two tidy dataframes for the results\n#'\n#' @param exposure A numeric vector for the exposure variable\n#' @param outcome A numeric vector for the outcome variable\n#' @param omics_lst A list of numeric matrices representing omics data\n#' @param covs A numeric matrix representing the covariates\n#'\n#' @return A list including two tidy dataframes summarizing the results of HIMA analysis\n#' and one vector indicating integration type \n#' one dataframe including the significant result of HIMA analysis with PCs as mediators.\n#' another dataframe including the result of feature correlation with significant PCs.\n#' \n#' @import dplyr\n#' @importFrom tidyr as_tibble\n#' @importFrom dplyr left_join\n#' @importFrom purrr map\n#' @importFrom stats prcomp cor\n#' @importFrom HIMA hima\n#' @importFrom base cumsum min sum scale apply\n#' @importFrom stringr str_replace\n#'\nmed_lf_early &lt;- function(exposure,\n                         outcome,\n                         omics_lst,\n                         covs,\n                         Y.family = \"gaussian\",\n                         M.family = \"gaussian\",\n                         fdr.level = 0.05) {\n  \n  # Give error if covs is NULL\n  if (is.null(covs)) {\n    stop(\"Currently, hima does not support analysis without covariates.\n         Please provide covariates.\")\n  }\n  \n  # Combines omics data into one dataframe\n  omics_lst_df &lt;- purrr::map(omics_lst, ~as_tibble(.x, rownames = \"name\"))\n  \n  # Meta data\n  meta_df &lt;- imap_dfr(omics_lst_df, ~tibble(omic_layer = .y, ftr_name = names(.x)))%&gt;%\n    filter(ftr_name != \"name\") %&gt;%\n    mutate(omic_num = case_when(str_detect(omic_layer, \"meth\") ~ 1, \n                                str_detect(omic_layer, \"transc\") ~ 2, \n                                str_detect(omic_layer, \"miR\") ~ 3,\n                                str_detect(omic_layer, \"pro\") ~ 4, \n                                str_detect(omic_layer, \"met\") ~ 5))\n  \n  # i. Obtain PCs----\n  omics_df_pca &lt;- prcomp(omics_df, center = TRUE, scale. = TRUE)\n  \n  # Calculate variance and proportion of variance explained by each PC\n  vars &lt;- apply(omics_df_pca$x, 2, var)\n  props &lt;- vars / sum(vars)\n  cum_props &lt;- cumsum(props)\n  \n  # Determine the number of PCs needed to explain &gt; 80% of the total variance\n  n_80_pct &lt;- min((1:length(cum_props))[cum_props &gt; 0.8])\n  \n  # The first PCs which explain &gt;80% of the variance are used as latent mediators\n  PCs &lt;- omics_df_pca$x[, 1:n_80_pct] %&gt;% scale()\n  \n  # ii. Perform HIMA with PCs as mediator----\n  \n  result_hima_comb_pc &lt;- hima(X  = exposure,\n                               Y = outcome,\n                               M = PCs,\n                               COV.XM = covs,\n                               COV.MY = covs,\n                               Y.family =  Y.family,\n                               M.family = M.family, \n                               scale = FALSE)\n  \n  \n  # Change to tibble and select significant PCs\n  result_hima_pca_early &lt;- as_tibble(result_hima_comb_pc, rownames = \"lf_num\") %&gt;% \n    filter(BH.FDR &lt; fdr.level) \n  \n  # Filter Significant PCs, Create scaled %TE variable\n  result_hima_pca_early_sig &lt;- result_hima_pca_early %&gt;% \n    mutate(\n      te_direction = if_else(beta&lt;0, -1*`% total effect`, `% total effect`), \n      `% Total Effect scaled` = 100*`% total effect`/sum(`% total effect`) %&gt;%\n        round(1), \n      multiomic_mthd = \"Early\") %&gt;%\n    mutate(lf_named = str_replace(lf_num, \"PC\", \"Joint Comp. \"),\n           lf_ordered = forcats::fct_reorder(lf_named, `te_direction`)) %&gt;%\n    rename(Alpha = alpha, \n           Beta = beta,\n           `TE (%)` = `% Total Effect scaled`) %&gt;%\n    mutate(omic_num = case_when(str_detect(lf_num, \"meth\") ~ 1, \n                                str_detect(lf_num, \"transc\") ~ 2, \n                                str_detect(lf_num, \"miR\") ~ 3,\n                                str_detect(lf_num, \"pro\") ~ 4, \n                                str_detect(lf_num, \"met\") ~ 5,\n                                TRUE ~ 0))\n  \n  \n  # ii correlation of features vs PC's --------------\n  # Extract variable correlation with principal components\n  var.cor &lt;- cor(omics_df, omics_df_pca$x)\n  \n  # Select only significant PCs\n  ftr_cor_sig_pcs &lt;- var.cor[,(colnames(var.cor) %in% \n                                 result_hima_pca_early_sig$lf_num)]\n  \n  ftr_cor_sig_pcs_df &lt;- ftr_cor_sig_pcs %&gt;%\n    as_tibble(rownames = \"feature\") %&gt;%\n    left_join(meta_df, by = c(\"feature\" = \"ftr_name\"))\n    \n  \n  res = list(result_hima_pca_early_sig = result_hima_pca_early_sig, \n             result_ftr_cor_sig_pcs_early = ftr_cor_sig_pcs_df,\n             integration_type = \" Early\")\n  return(res)\n}\n\n\n\n\n6.2.2 Intermediate Integration of omics datasets\n\n\nCode\n#' Perform a joint dimensionality reduction step \n#' using Joint and Individual Variance Explained (JIVE). \n#' Following the joint dimensionality reduction step, \n#' conduct mediation analysis.\n\n\n#' Given exposure, outcome and multiple omics data,\n#' function runs HIMA mediation analysis with latent factors in intermediate integration\n#' and returns a list including two tidy dataframes for the results\n#'\n#' @param exposure A numeric vector for the exposure variable\n#' @param outcome A numeric vector for the outcome variable\n#' @param omics_lst A list of numeric matrices representing omics data\n#' @param jive.rankJ Number of joint factors for JIVE to estimate. If NULL, \n#' then jive estimates the optimum number of joint factors.\n#' @param jive.rankA Number of individual factors for JIVE to estimate. If NULL,\n#' then jive estimates this variable. Should be a numeric vector with the same \n#' length as dim(omics_lst)   \n#' @param covs A numeric matrix representing the covariates\n#'\n#' @return A list including two tidy dataframes summarizing the results of HIMA analysis\n#' and one vector indicating integration type.\n#' one dataframe including the significant result of \n#' HIMA analysis with latent factors as mediators.\n#' another dataframe including the result of feature correlation with significant PCs.\n#' \n#' @import dplyr\n#' @importFrom tidyr as_tibble\n#' @importFrom dplyr left_join\n#' @importFrom r.jive jive\n#' @importFrom stats prcomp cor\n#' @importFrom HIMA hima\n#' @importFrom base min sum scale apply svd diag\n#' @importFrom stringr str_replace\n#'\nmed_lf_intermediate &lt;- function(exposure, \n                                outcome,\n                                omics_lst,\n                                covs,\n                                jive.rankJ = NULL,\n                                jive.rankA = NULL,  \n                                Y.family = \"gaussian\",\n                                M.family = \"gaussian\",\n                                fdr.level = 0.05) {\n\n  # Give error if covs is NULL\n  if (is.null(covs)) {\n    stop(\"Currently, hima does not support analysis without covariates.\n         Please provide covariates.\")\n  }\n  \n  # Combines omics data into one dataframe\n  omics_lst_df &lt;- purrr::map(omics_lst, ~as_tibble(.x, rownames = \"name\"))\n  \n  # Meta data\n  meta_df &lt;- imap_dfr(omics_lst_df, ~tibble(omic_layer = .y, ftr_name = names(.x)))%&gt;%\n    filter(ftr_name != \"name\") %&gt;%\n    mutate(omic_num = case_when(str_detect(omic_layer, \"meth\") ~ 1, \n                                str_detect(omic_layer, \"transc\") ~ 2, \n                                str_detect(omic_layer, \"miR\") ~ 3,\n                                str_detect(omic_layer, \"pro\") ~ 4, \n                                str_detect(omic_layer, \"met\") ~ 5))\n  # Transpose omics matrices\n  omics_t &lt;- lapply(omics_lst, t)\n  \n  # Rename omics datasets\n  names(omics_t) = names(omics_lst)\n  \n  # Run JIVE----- \n  if (is.null(jive.rankJ) | is.null(jive.rankA)) {\n    jive.message &lt;- \"Step A) Starting JIVE analysis...\"\n  } else {jive.message &lt;- \"Step A) Starting JIVE analysis with ranks given...\"}\n  message(paste0(jive.message, \"    (\", \n                 Sys.time() %&gt;% \n                   format(\"%H:%M:%S\") %&gt;% \n                   str_split(\":\") %&gt;% \n                   unlist() %&gt;% \n                   .[1:3] %&gt;% \n                   paste(collapse = \":\"), \n                 \")\\n\"))\n  \n  result_jive2 &lt;- jive(data = omics_t,\n                       rankJ = jive.rankJ,\n                       rankA = jive.rankA,\n                       method = \"given\",\n                       conv = 1e-04,\n                       maxiter = 100,\n                       showProgress = FALSE)\n  \n  # Get the components from JIVE\n  # Function to extract joint and individual PCs ----\n  get_PCs_jive &lt;- function (result){\n    # Number of joint factors \n    n_joint = result$rankJ\n    # Number of individual factors\n    n_indiv = result$rankA\n    # Get number of data matrices in result\n    l &lt;- length(result$data)    \n    # Calculate total number of PCs to compute\n    nPCs = n_joint + sum(n_indiv)    \n    # Initialize matrix to hold PC scores\n    PCs = matrix(nrow = nPCs, ncol = dim(result$data[[1]])[2])    \n    # Initialize vector to hold PC names\n    PC_names = rep(\"\", nPCs)    \n    # If joint structure is present\n    if (n_joint &gt; 0) {   \n      # Compute SVD on joint structure\n      SVD = svd(do.call(rbind, result$joint), nu = n_joint, nv = n_joint)\n      # Compute PC scores for joint structure\n      PCs[1:n_joint,] = diag(SVD$d)[1:n_joint, 1:n_joint] %*% t(SVD$v[, 1:n_joint])    \n      # Assign names to joint PCs\n      PC_names[1:n_joint] = paste(\"Joint \", 1:n_joint)    \n    }\n    # Loop over data matrices\n    for (i in 1:l) {    \n      # If individual structure is present for this matrix\n      if (n_indiv[i] &gt; 0) {    \n        # Compute SVD on individual structure\n        SVD = svd(result$individual[[i]], nu = n_indiv[i], \n                  nv = n_indiv[i])    \n        # Get indices for PCs corresponding to this data matrix\n        indices = (n_joint + sum(n_indiv[0:(i - 1)]) + 1):(n_joint + \n                                                             sum(n_indiv[0:i]))    \n        # Compute PC scores for individual structure\n        PCs[indices, ] = diag(SVD$d)[1:n_indiv[i], 1:n_indiv[i]] %*% \n          t(SVD$v[, 1:n_indiv[i]])   \n        # Assign names to individual PCs\n        PC_names[indices] = paste0(names(result$data)[i], \n                                   \"_\", 1:n_indiv[i]) \n      }\n    }\n    # Rename PCs\n    rownames(PCs) &lt;- PC_names %&gt;%\n      str_replace(\"  \", \"_\")\n    # Transpose and change to data.frame\n    out &lt;- as.data.frame(t(PCs))\n    # Return output\n    return(out)\n  }\n  \n  factors_jive &lt;- get_PCs_jive(result_jive2) %&gt;% \n    dplyr::mutate(across(everything(), ~as.vector(scale(.))))\n  \n  # run mediation analysis------\n  message(paste0(\"Step B) Starting hima on JIVE factors...    (\", \n                 Sys.time() %&gt;% \n                   format(\"%H:%M:%S\") %&gt;% \n                   str_split(\":\") %&gt;% \n                   unlist() %&gt;% \n                   .[1:3] %&gt;% \n                   paste(collapse = \":\"), \n                \")\\n\"))\n  \n  # Select only HH:MM:SS from Sys.time()\n  \n  \n  \n  result_hima_jive &lt;- hima(X = exposure,\n                           Y = outcome,\n                           M = factors_jive,\n                           COV.MY = covs,\n                           COV.XM = covs,\n                           Y.family = c(\"gaussian\"),\n                           M.family = c(\"gaussian\"), \n                           verbose = FALSE,\n                           scale = FALSE)\n  \n  # Modify and filter significant                \n  result_hima_jive_1 &lt;- result_hima_jive %&gt;% \n    rownames_to_column(\"lf_num\") %&gt;% \n    mutate(multiomic_mthd = \"Intermediate\",\n           ind_joint = str_split_fixed(lf_num, fixed(\"_\"), 2)[,1], \n           ind_joint_num = case_when(ind_joint == \"Joint\" ~ 1, \n                                     ind_joint == \"methylome\" ~ 2,\n                                     ind_joint == \"transcriptome\" ~ 3)) %&gt;% \n    dplyr::select(multiomic_mthd, everything())\n  \n  # Filter significant components and create scaled %TE variable\n  result_hima_jive_sig &lt;-  result_hima_jive_1 %&gt;% \n    filter(BH.FDR&lt;fdr.level) %&gt;%   \n    mutate(`% Total Effect scaled` =\n             round(100*`% total effect`/sum(`% total effect`),1),\n           te_direction = if_else(beta &lt; 0, \n                                  -1 * `% total effect`, \n                                  `% total effect`)) %&gt;%\n    mutate(lf_named = str_replace(toTitleCase(lf_num), \"_\", \" Comp. \"),\n           lf_ordered = forcats::fct_reorder(lf_named, `te_direction`)) %&gt;%\n    rename(Alpha = alpha, \n           Beta = beta,\n           `TE (%)` = `% Total Effect scaled`)%&gt;%\n    mutate(omic_num = case_when(str_detect(lf_num, \"meth\") ~ 1, \n                                str_detect(lf_num, \"transc\") ~ 2, \n                                str_detect(lf_num, \"miR\") ~ 3,\n                                str_detect(lf_num, \"pro\") ~ 4, \n                                str_detect(lf_num, \"met\") ~ 5,\n                                TRUE ~ 0))\n  \n  # correlation of features vs JIVE factors --------------\n  # Extract variable correlation with JIVE Factors\n  var.cor &lt;- cor(omics_df, factors_jive) \n  \n  # Select only significant PCs\n  ftr_cor_sig_pcs_jive &lt;- var.cor[,(colnames(var.cor) %in% \n                                          result_hima_jive_sig$lf_num)] \n  \n  ftr_cor_sig_pcs_jive_df &lt;- ftr_cor_sig_pcs_jive %&gt;%\n    as_tibble(rownames = \"feature\") %&gt;%\n    left_join(meta_df, by = c(\"feature\" = \"ftr_name\"))\n  \n  res = list(result_hima_jive_sig = result_hima_jive_sig, \n             result_ftr_cor_sig_pcs_jive = ftr_cor_sig_pcs_jive_df,\n             integration = \"Intermediate\")\n  return(res)\n}\n\n\n\n\n6.2.3 Late Integration of omics datasets\n\n\nCode\n#' Conduct principal component analysis (PCA) as a dimensionality reduction step  \n#' on each omics layer separately \n#' and selected the top i principal components which explained &gt;80% of the variance. \n#' Following the joint dimensionality reduction step, conduct mediation analysis.\n\n#' Given exposure, outcome and multiple omics data,\n#' function runs HIMA mediation analysis with latent factors in late integration\n#' and returns a list including two tidy dataframes for the results\n#'\n#' @param exposure A numeric vector for the exposure variable\n#' @param outcome A numeric vector for the outcome variable\n#' @param omics_lst A list of numeric matrices representing omics data\n#' @param covs A numeric matrix representing the covariates\n#'\n#' @return A list including two tidy dataframes and one vector. \n#' Two tidy dataframes summarized the results of HIMA analysis\n#' one dataframe including the significant result of \n#' HIMA analysis with PCs as mediators for each omics layer.\n#' another dataframe including the result of feature correlation with significant PCs. \n#' One vector includes the integration type. \n#' \n#' @import dplyr\n#' @importFrom tidyr as_tibble\n#' @importFrom dplyr left_join\n#' @importFrom purrr map2 mapreduce\n#' @importFrom stats prcomp cor\n#' @importFrom HIMA hima\n#' @importFrom base cumsum min sum scale apply\n#' @importFrom stringr str_replace\n#'\nmed_lf_late &lt;- function(exposure,\n                        outcome,\n                        omics_lst,\n                        covs, \n                        Y.family = \"gaussian\",\n                        M.family = \"gaussian\",\n                        fdr.level = 0.05) {\n  # Give error if covs is NULL\n  if (is.null(covs)) {\n    stop(\"Currently, hima does not support analysis without covariates.\n         Please provide covariates.\")\n  }\n  \n  # Combines omics data into one dataframe\n  omics_lst_df &lt;- purrr::map(omics_lst, ~as_tibble(.x, rownames = \"name\"))\n  \n  # Meta data\n  meta_df &lt;- imap_dfr(omics_lst_df, ~tibble(omic_layer = .y, ftr_name = names(.x)))%&gt;%\n    filter(ftr_name != \"name\") %&gt;%\n    mutate(omic_num = case_when(str_detect(omic_layer, \"meth\") ~ 1, \n                                str_detect(omic_layer, \"transc\") ~ 2, \n                                str_detect(omic_layer, \"miR\") ~ 3,\n                                str_detect(omic_layer, \"pro\") ~ 4, \n                                str_detect(omic_layer, \"met\") ~ 5))\n  \n  # Define function to run PCA on a matrix and return loadings and scores\n  run_pca &lt;- function(mat, omic_name) {\n    # perform PCA on input matrix with scaling\n    pca &lt;- prcomp(mat, scale. = TRUE)\n    # calculate variance explained by each principal component\n    vars &lt;- apply(pca$x, 2, var)\n    props &lt;- vars / sum(vars)\n    # calculate cumulative proportion of variance explained\n    cum_props &lt;- cumsum(props)\n    \n    # determine the number of principal components needed to explain 80% of the variance\n    n_80_pct &lt;- min((1:length(cum_props))[cum_props &gt; 0.8])\n    # create a dataframe of scores for the principal components and scale them\n    PCs &lt;- pca$x[, 1:n_80_pct] %&gt;% scale() %&gt;% as.data.frame()\n    colnames(PCs) &lt;- paste0(omic_name, \"_\", colnames(PCs))\n    # create a dataframe of loadings for the principal components and scale them\n    loadings_df &lt;- pca$rotation[, 1:n_80_pct] %&gt;% scale() %&gt;% as.data.frame()\n    colnames(loadings_df) &lt;- paste0(omic_name, \"_\", colnames(loadings_df))\n    loadings_df &lt;- rownames_to_column(loadings_df, \"feature\")\n    \n    # Including all PCs \n    # create a dataframe of scores for the principal components and scale them\n    PCs_full &lt;- pca$x %&gt;% scale() %&gt;% as.data.frame()\n    colnames(PCs_full) &lt;- paste0(omic_name, \"_\", colnames(PCs_full))\n    \n    # create a dataframe of proportion of variance explained by each principal component\n    props_df &lt;- data.frame(pc_num = paste0(omic_name, \"_\",\n                                           names(props)),\n                           pc_var_explained = props)\n    rownames(props_df) &lt;- NULL\n    # return a list of results\n    return(list(loadings = loadings_df, scores = PCs, scores_full = PCs_full,\n                n_pcs_80_pct = n_80_pct, pc_var_explained = props_df))\n  }\n  # i. get PCs and HIMA -----\n  # PCA scores: Apply function to each matrix in the list and collect \n  scores_list_late_int &lt;-  map2(omics_lst, \n                                names(omics_lst), \n                                ~run_pca(.x, .y)$scores)\n  scores_df &lt;- purrr::reduce(scores_list_late_int, cbind) %&gt;% as.data.frame()\n  \n  # Loadings: Apply function to each matrix in the list and collect PC \n  loadings_list_late_int &lt;- map2(omics_lst, \n                                 names(omics_lst),\n                                 ~run_pca(.x, .y)$loadings)\n  loadings_df &lt;- purrr::reduce(loadings_list_late_int, full_join, by = \"feature\")\n  \n  # Number of PCs explain &gt;80%: Get number of PCs for each omic\n  late_int_pcs_80 &lt;- purrr::map(omics_lst, ~run_pca(.x, NULL)$n_pcs_80_pct) %&gt;%\n    bind_rows()\n  \n  # ii. run HIMA with the current dataset and principal components ----\n  result_hima_late_integration &lt;- hima(X = exposure,\n                                       Y = outcome,\n                                       M = scores_df, \n                                       COV.MY = covs,\n                                       COV.XM = covs,\n                                       Y.family = c(\"gaussian\"),\n                                       M.family = c(\"gaussian\"), \n                                       scale = FALSE) \n  \n  # Filter significant pcs, create scaled %TE variable\n  result_hima_late_sig &lt;- result_hima_late_integration %&gt;%\n    as_tibble(rownames = \"lf_num\") %&gt;%\n    filter(BH.FDR &lt; 0.05) %&gt;%\n    mutate(\n      te_direction = if_else(beta&lt;0, -1*`% total effect`, `% total effect`), \n      `% Total Effect scaled` = 100*`% total effect`/sum(`% total effect`)) \n  \n  result_hima_late_sig &lt;- result_hima_late_sig  %&gt;% \n    mutate(lf_numeric = str_split_fixed(lf_num, fixed(\"_\"), 2)[,2],\n           omic_layer = str_split_fixed(lf_num, fixed(\"_\"), 2)[,1] %&gt;%\n             str_to_sentence(),\n           multiomic_mthd = \"Late\")%&gt;%\n    mutate(omic_layer = str_replace(omic_layer, \"Mirna\", \"miRNA\" ),\n           omic_pc = str_c(omic_layer, \" \", lf_numeric) %&gt;%\n             str_replace(\"PC\", \"Comp. \")) %&gt;%\n    mutate(lf_ordered = forcats::fct_reorder(omic_pc, `te_direction`)) %&gt;%\n    dplyr::select(multiomic_mthd, omic_pc, omic_layer, lf_num, lf_ordered,\n                  alpha, beta, `% Total Effect scaled`) %&gt;%\n    rename(Alpha = alpha, \n           Beta = beta,\n           `TE (%)` = `% Total Effect scaled`)%&gt;%\n    mutate(omic_num = case_when(str_detect(lf_num, \"meth\") ~ 1, \n                                str_detect(lf_num, \"transc\") ~ 2, \n                                str_detect(lf_num, \"miR\") ~ 3,\n                                str_detect(lf_num, \"pro\") ~ 4, \n                                str_detect(lf_num, \"met\") ~ 5))\n  \n  \n  # Extract variable correlation with principal components\n  scores_full_list_late_int &lt;- map2(omics_lst, \n                                    names(omics_lst),\n                                    ~run_pca(.x, .y)$scores_full)\n  \n  scores_df_full &lt;- purrr::reduce(scores_full_list_late_int, cbind) %&gt;% as.data.frame()\n  \n  # Get correlation of omics and PCs by omic layer\n  var.cor &lt;- map_df(names(omics_lst), function(type) {\n    cor(omics_lst[[type]], scores_full_list_late_int[[type]]) %&gt;%\n      as.data.frame()\n  })\n  \n  # Select only significant PCs\n  ftr_cor_sig_pcs_late &lt;- var.cor %&gt;%\n    dplyr::select(result_hima_late_sig$lf_num) %&gt;%\n    as_tibble(rownames = \"feature\") %&gt;%\n    left_join(meta_df, by = c(\"feature\" = \"ftr_name\"))\n  \n  res = list(result_hima_late_sig = result_hima_late_sig, \n             result_ftr_cor_sig_pcs_late = ftr_cor_sig_pcs_late,\n             intergration_type = \"Late\")\n  return(res)\n  \n}\n\n\n\n\n6.2.4 Plot Mediation\n\n\nCode\n#' Plot result of mediation analysis with latent factors\n#' \n#' Given a list including two tidy dataframes and one integration type vector \n#' summarizing  mediation analysis result\n#' function runs plotting and returns a plot\n#'\n#' @param med_lf_list A list including two tidy dataframes \n#' summarizing the results of HIMA analysis\n#' and one vector indicating integration type\n\n#'\n#' @return a figure of the result of mediation with latent factors in given integration\n#' \n#' @import dplyr\n#' @importFrom dplyr left_join\n#' @importFrom ggplot2 ggplot\n#' @importFrom base apply\n#' \n\nplot_med_lf &lt;- function(med_lf_list) {\n  \n  # Panel A Bargraph of mediation effects of latent factors --------------\n  med_long &lt;- med_lf_list[[1]]%&gt;%\n    pivot_longer(cols = c(Alpha, Beta, `TE (%)`))\n  \n  # Plot \n  panel_a &lt;- ggplot(med_long, aes(x = lf_ordered, y = value)) +\n    geom_bar(stat = \"identity\", fill = \"grey50\") + \n    geom_hline(yintercept = 0) +\n    facet_grid(name ~ omic_num, scales = \"free\", space = \"free_x\", switch = \"y\") + \n    ggh4x::facetted_pos_scales(\n      y = list(name == \"Alpha\"  ~ scale_y_continuous(\n        limits = c(-.45,.45), breaks = c(-0.4, 0, .4)),\n        name == \"Beta\"   ~ scale_y_continuous(\n          limits = c(-.45,.45), breaks = c(-0.4, 0, .4)),\n        name == \"TE (%)\" ~ scale_y_continuous(\n          limits = c(-1,55), n.breaks = 4))) + \n    theme(axis.title = element_blank(), \n          strip.placement = \"outside\",\n          strip.text.x = element_blank(),\n          strip.text.y = element_text(angle = 0, size = 9),\n          axis.text.x = element_blank(),\n          strip.background = element_blank(),\n          axis.text.y = element_text(size = 8))\n  \n  # Panel B: heatmap of correlation of features vs PC's --------------\n  \n  # Select features for plots -------\n  ## Select rows with values in the top 10 of their respective columns \n  \n  top &lt;- apply(med_lf_list[[2]] %&gt;% \n                 select(-omic_layer, -omic_num) %&gt;% \n                 janitor::remove_empty(which = \"rows\") %&gt;%\n                 column_to_rownames(\"feature\"), 2,\n               function(x) x %in% tail(sort(abs(x)), 10))\n  \n  ## Filter selected rows\n  ftr_cor_sig_lf_top_ft &lt;- med_lf_list[[2]][which(rowSums(top) &gt; 0), ] \n  \n  # Pivot longer\n  ftr_cor_sig_lf_top_ft_l &lt;-\n    ftr_cor_sig_lf_top_ft %&gt;%\n    pivot_longer(cols = all_of(med_lf_list[[1]]$lf_num),\n                 names_to = \"lf_num\",\n                 values_to = \"Correlation\")\n  \n  # Change features which are in wrong JIVE individual component to zero\n  if(med_lf_list[[3]] == \"Intermediate\") {\n    ftr_cor_sig_lf_top_ft_l &lt;- ftr_cor_sig_lf_top_ft_l %&gt;%\n      mutate(\n        in_ind_omic = str_sub(lf_num, 1, 5) == str_sub(omic_layer, 1, 5),\n        Correlation = ifelse(in_ind_omic | str_detect(lf_num, \"Joint\"),\n                             Correlation, NA)) \n  }\n  \n  # Join with long format of mediation effects of latent factors \n  # to get the ordered latent factor\n  panel_b_dat_top_ft &lt;- left_join(ftr_cor_sig_lf_top_ft_l,\n                                  med_long %&gt;%\n                                    filter(name == \"Alpha\") %&gt;%\n                                    dplyr::select(lf_num, lf_ordered),\n                                  by = \"lf_num\") %&gt;%\n    mutate(omic_num2 = case_when(str_detect(lf_num, \"meth\") ~ 1, \n                                 str_detect(lf_num, \"transc\") ~ 2, \n                                 str_detect(lf_num, \"miR\") ~ 3,\n                                 str_detect(lf_num, \"pro\") ~ 4, \n                                 str_detect(lf_num, \"met\") ~ 5,\n                                 TRUE ~ 0))\n  \n  \n  # Plot\n  panel_b &lt;- ggplot(data = panel_b_dat_top_ft,\n                    aes(y = feature,\n                        x = lf_ordered, \n                        fill = Correlation)) +\n    geom_tile(color = \"white\") +\n    facet_grid(omic_layer ~ omic_num2, scales = \"free\", space = \"free\") +\n    scale_fill_gradient2(low  = \"blue\",\n                         mid  = \"white\",\n                         high = \"red\",\n                         midpoint = 0,\n                         limits = c(-1, 1),\n                         breaks = c(-1, 0, 1),\n                         na.value = \"grey50\") +\n    theme(\n      axis.text.x = element_text(size = 8,angle = 90, hjust = 1, vjust = .5),\n      axis.text.y = element_text(size = 8),\n      strip.text = element_blank(),\n      axis.title = element_blank(), \n      axis.ticks.x = element_blank(),\n      legend.position = \"none\",\n      text = element_text(size = 8)) \n  \n  # Combine Figures \n  p &lt;- cowplot::plot_grid(\n    NULL, panel_a,  NULL, panel_b, \n    ncol = 1, align = \"v\", axis = \"lr\",\n    rel_heights  = c(.05, .6, .1, 1.75),\n    labels = c(\"a)\",\"\", \"b) \"))\n  \n  return(p)\n}"
  },
  {
    "objectID": "appendix_code.html#integratedquasi-mediation-analysis-code",
    "href": "appendix_code.html#integratedquasi-mediation-analysis-code",
    "title": "6  Supplemental Code",
    "section": "6.3 Integrated/Quasi Mediation Analysis Code",
    "text": "6.3 Integrated/Quasi Mediation Analysis Code\n\n6.3.1 Early Integration of omics datasets\n\n\nCode\n#' Plot Sankey Diagram for LUCID in Early integration\n#' \n#' Given an object of class from LUCID\n#'\n#' @param lucid_fit1  an object of class from LUCID\n#' @param text_size  size of the text in sankey diagram\n#'\n#' @return a Sankey Diagram for LUCID in Early integration\n#'\n#' @import dplyr\n#' @importFrom ggplot2 ggplot\n\n\n\nsankey_early_integration &lt;- function(lucid_fit1, text_size = 15) {\n  # Get sankey dataframe ----\n  get_sankey_df &lt;- function(x,\n                            G_color = \"dimgray\", \n                            X_color = \"#eb8c30\",\n                            Z_color = \"#2fa4da\", \n                            Y_color = \"#afa58e\", \n                            pos_link_color = \"#67928b\", \n                            neg_link_color = \"#d1e5eb\", \n                            fontsize = 10) {\n    K &lt;- x$K\n    var.names &lt;- x$var.names\n    pars &lt;- x$pars\n    dimG &lt;- length(var.names$Gnames)\n    dimZ &lt;- length(var.names$Znames)\n    valueGtoX &lt;- as.vector(t(x$pars$beta[, -1]))\n    valueXtoZ &lt;- as.vector(t(x$pars$mu))\n    valueXtoY &lt;- as.vector(x$pars$gamma$beta)[1:K]\n    \n    # GtoX\n    GtoX &lt;- data.frame(\n      source = rep(x$var.names$Gnames, K), \n      target = paste0(\"Latent Cluster\", \n                      as.vector(sapply(1:K, function(x) rep(x, dimG)))), \n      value = abs(valueGtoX), \n      group = as.factor(valueGtoX &gt; 0))\n    \n    # XtoZ\n    XtoZ &lt;- data.frame(\n      source = paste0(\"Latent Cluster\", \n                      as.vector(sapply(1:K, \n                                       function(x) rep(x, dimZ)))), \n      target = rep(var.names$Znames, \n                   K), value = abs(valueXtoZ),\n      group = as.factor(valueXtoZ &gt; \n                          0))\n    \n    # subset top 25% of each omics layer\n    top25&lt;- XtoZ %&gt;%\n      filter(source == \"Latent Cluster1\") %&gt;%\n      mutate(omics = case_when(grepl(\"cg\", target) ~ \"Methylation\",\n                               grepl(\"tc\", target) ~ \"Transcriptome\",\n                               grepl(\"miR\", target) ~ \"miRNA\")) %&gt;%\n      group_by(omics) %&gt;%\n      arrange(desc(value)) %&gt;%\n      slice(1:7) %&gt;%\n      ungroup()\n    \n    XtoZ_sub&lt;- XtoZ %&gt;%\n      filter(target %in% top25$target)\n    \n    \n    # XtoY\n    XtoY &lt;- data.frame(source = paste0(\"Latent Cluster\", 1:K), \n                       target = rep(var.names$Ynames, K), value = abs(valueXtoY), \n                       group = as.factor(valueXtoY &gt; 0))\n    links &lt;- rbind(GtoX, XtoZ_sub, XtoY)\n    # links &lt;- rbind(GtoX, XtoZ, XtoY)\n    \n    nodes &lt;- data.frame(\n      name = unique(c(as.character(links$source), \n                      as.character(links$target))), \n      group = as.factor(c(rep(\"exposure\",\n                              dimG), rep(\"lc\", K), rep(\"biomarker\", nrow(XtoZ_sub)/2), \"outcome\")))\n    # group = as.factor(c(rep(\"exposure\", \n    # dimG), rep(\"lc\", K), rep(\"biomarker\", dimZ), \"outcome\")))\n    ## the following two lines were used to exclude covars from the plot\n    links &lt;- links %&gt;% filter(!grepl(\"cohort\", source) & \n                                !grepl(\"age\", source) & \n                                !grepl(\"fish\", source) &\n                                !grepl(\"sex\", source))\n    nodes &lt;- nodes %&gt;% filter(!grepl(\"cohort\", name) &\n                                !grepl(\"age\", name) & \n                                !grepl(\"fish\", name) &\n                                !grepl(\"sex\", name)) \n    \n    links$IDsource &lt;- match(links$source, nodes$name) - 1\n    links$IDtarget &lt;- match(links$target, nodes$name) - 1\n    \n    color_scale &lt;- data.frame(\n      domain = c(\"exposure\", \"lc\", \"biomarker\", \n                 \"outcome\", \"TRUE\", \"FALSE\"), \n      range = c(G_color, X_color, \n                Z_color, Y_color, pos_link_color, neg_link_color))\n    \n    sankey_df = list(links = links, \n                     nodes = nodes)\n    return(sankey_df)\n  }\n  # 1. Get sankey dataframes ----\n  sankey_dat &lt;- get_sankey_df(lucid_fit1)\n  n_omics &lt;- length(lucid_fit1$var.names$Znames)\n  # link data\n  links &lt;- sankey_dat[[\"links\"]] \n  # node data\n  nodes &lt;- sankey_dat[[\"nodes\"]] \n  \n  nodes1 &lt;- nodes %&gt;% \n    mutate(group = case_when(str_detect(name,\"Cluster\") ~ \"lc\",\n                             str_detect(name, \"cg\") ~ \"CpG\",\n                             str_detect(name, \"outcome\") ~ \"outcome\",\n                             str_detect(name, \"pro\") ~ \"Prot\",\n                             str_detect(name, \"met\") ~ \"Met\",\n                             str_detect(name, \"tc\") ~ \"TC\",\n                             str_detect(name, \"miR\") ~ \"miRNA\",\n                             str_detect(name, \"G1\") ~ \"exposure\"),\n           name = ifelse(name == \"G1\", \"Hg\",name))\n  links1 &lt;- links %&gt;%\n    mutate(source = ifelse(source == \"G1\", \"Hg\",source))\n  # 6. Plotly Version ----\n  \n  ## 6.1 Set Node Color Scheme: ----\n  color_pal_sankey &lt;- matrix(\n    c(\"exposure\", sankey_colors$range[sankey_colors$domain == \"exposure\"],\n      \"lc\",       \"#b3d8ff\",\n      \"CpG\",     sankey_colors$range[sankey_colors$domain == \"layer1\"],\n      \"TC\",      sankey_colors$range[sankey_colors$domain == \"layer2\"],\n      \"miRNA\", sankey_colors$range[sankey_colors$domain == \"layer3\"],\n      \"outcome\",  sankey_colors$range[sankey_colors$domain == \"Outcome\"]), \n    ncol = 2, byrow = TRUE) %&gt;%\n    as_tibble(.name_repair = \"unique\") %&gt;% \n    janitor::clean_names() %&gt;%\n    dplyr::rename(group = x1, color = x2)\n  \n  # Add color scheme to nodes\n  nodes_new_plotly &lt;- nodes1 %&gt;% \n    left_join(color_pal_sankey) %&gt;%\n    mutate(\n      x = case_when(\n        group == \"exposure\" ~ 0,\n        str_detect(name, \"Cluster\") ~ 1/3,\n        str_detect(name, \"cg\")|\n          str_detect(name, \"tc\")|\n          str_detect(name, \"miR\")|\n          str_detect(name, \"outcome\")~ 2/3\n      ))\n  \n  nodes_new_plotly1 &lt;- nodes_new_plotly %&gt;%\n    # Modify names of features for plotting\n   dplyr::select(group, color, x, name)%&gt;% \n    mutate(name = case_when(name == \"value\" ~ \"&lt;b&gt;Hg&lt;/b&gt;\",\n                            name == \"Latent Cluster1\" ~ \"&lt;b&gt;Joint Omics\\nProfile 0&lt;/b&gt;\",\n                            name == \"Latent Cluster2\" ~ \"&lt;b&gt;Joint Omics\\nProfile 1&lt;/b&gt;\",\n                            TRUE ~ name))\n    \n  \n  ## 6.2 Get links for Plotly, set color ----\n  links_new &lt;- links1  %&gt;%\n    mutate(\n      link_color = case_when(\n        # Ref link color\n        value == 0 ~     \"#f3f6f4\",\n        # # Cluster \n        # str_detect(source, \"Cluster1\") &  group == TRUE  ~  \"#706C6C\",\n        # str_detect(source, \"Cluster1\") &  group == FALSE ~  \"#D3D3D3\",\n        # str_detect(source, \"Cluster2\") &  group == TRUE  ~  \"#706C6C\",\n        # str_detect(source, \"Cluster2\") &  group == FALSE ~  \"#D3D3D3\",\n        ##############\n        # Exposure\n        str_detect(source, \"Hg\") &  group == TRUE  ~  \"red\",\n            # Outcome\n        str_detect(target, \"outcome\") &  group == TRUE  ~  \"red\",\n        # Methylation \n        str_detect(target, \"tc\") &  group == TRUE  ~  \"#bf9000\",\n        str_detect(target, \"tc\") &  group == FALSE ~  \"#ffd966\",\n        # Transcriptome\n        str_detect(target, \"cg\") &  group == TRUE  ~  \"#38761d\",\n        str_detect(target, \"cg\") &  group == FALSE ~  \"#b6d7a8\",\n        # proteome\n        str_detect(target, \"miR\") &  group == TRUE  ~  \"#a64d79\",\n        str_detect(target, \"miR\") &  group == FALSE ~  \"#ead1dc\",\n        ##\n        group == FALSE ~ \"#D3D3D3\", # Negative association\n        group == TRUE ~  \"#706C6C\")) # Positive association\n  \n  links_new1&lt;- links_new %&gt;%\n   dplyr::select(colnames(links_new), target)\n    \n  plotly_link &lt;- list(\n    source = links_new1$IDsource,\n    target = links_new1$IDtarget,\n    value = links_new1$value+.00000000000000000000001, \n    color = links_new1$link_color)  \n  \n  # Get list of nodes for Plotly\n  plotly_node &lt;- list(\n    label = nodes_new_plotly1$name, \n    color = nodes_new_plotly1$color,\n    pad = 15,\n    thickness = 20,\n    line = list(color = \"black\",width = 0.5),\n    x = nodes_new_plotly1$x, \n    # y = c(0.01, \n    #       0.3, 0.7, # clusters\n    #       seq(from = .01, to = 1, by = 0.04)[1:(dimZ * 0.25)], # biomaker\n    #       .95\n    y = c(0.01,\n          0.1, 0.5, # clusters\n          seq(from = .05, to = 1, by = 0.04)[1:21],\n          # seq(from = (.01+0.06*7), to = 1, by = 0.08)[1:5],\n          # 0.9,\n          # biomaker\n          0.98\n  ))\n  \n  \n  ## 6.3 Plot Figure ----\n  (fig &lt;- plot_ly(\n    type = \"sankey\",\n    domain = list(\n      x =  c(0,1),\n      y =  c(0,1)),\n    orientation = \"h\",\n    node = plotly_node,\n    link = plotly_link))\n  \n  (fig &lt;- fig %&gt;% layout(\n    # title = \"Basic Sankey Diagram\",\n    font = list(\n      size = text_size\n    ))\n  )\n  return(fig)\n}\n\n\n\n\n6.3.2 Intermediate Integration of omics datasets\n\n\n6.3.3 Late Integration of omics datasets\n\n\nCode\n# Plot Lucid In Serial Function ------\nsource(fs::path(dir_proj, \"functions\", \"lucid_reorder_plot_without_y.R\"))\n\n# Get sankey dataframe\nget_sankey_df &lt;- function(x,\n                          G_color = \"dimgray\", \n                          X_color = \"#eb8c30\",\n                          Z_color = \"#2fa4da\", \n                          Y_color = \"#afa58e\", \n                          pos_link_color = \"#67928b\", \n                          neg_link_color = \"#d1e5eb\", \n                          fontsize = 7) {\n  K &lt;- x$K\n  var.names &lt;- x$var.names\n  pars &lt;- x$pars\n  dimG &lt;- length(var.names$Gnames)\n  dimZ &lt;- length(var.names$Znames)\n  valueGtoX &lt;- as.vector(t(x$pars$beta[, -1]))\n  valueXtoZ &lt;- as.vector(t(x$pars$mu))\n  valueXtoY &lt;- as.vector(x$pars$gamma$beta)[1:K]\n  \n  # GtoX\n  GtoX &lt;- data.frame(\n    source = rep(x$var.names$Gnames, K), \n    target = paste0(\"Latent Cluster\", \n                    as.vector(sapply(1:K, function(x) rep(x, dimG)))), \n    value = abs(valueGtoX), \n    group = as.factor(valueGtoX &gt; 0))\n  \n  # XtoZ\n  XtoZ &lt;- data.frame(\n    source = paste0(\"Latent Cluster\", \n                    as.vector(sapply(1:K, \n                                     function(x) rep(x, dimZ)))), \n    target = rep(var.names$Znames, \n                 K), value = abs(valueXtoZ),\n    group = as.factor(valueXtoZ &gt; \n                        0))\n  # XtoY\n  XtoY &lt;- data.frame(source = paste0(\"Latent Cluster\", 1:K), \n                     target = rep(var.names$Ynames, K), value = abs(valueXtoY), \n                     group = as.factor(valueXtoY &gt; 0))\n  \n  links &lt;- rbind(GtoX, XtoZ, XtoY)\n  \n  nodes &lt;- data.frame(\n    name = unique(c(as.character(links$source), \n                    as.character(links$target))), \n    group = as.factor(c(rep(\"exposure\", \n                            dimG), rep(\"lc\", K), rep(\"biomarker\", dimZ), \"outcome\")))\n  \n  ## the following two lines were used to exclude covars from the plot #HW added\n  links &lt;- links %&gt;% filter(!grepl(\"cohort\", source) & \n                              !grepl(\"age\", source) & \n                              !grepl(\"fish\", source) &\n                              !grepl(\"sex\", source))\n  nodes &lt;- nodes %&gt;% filter(!grepl(\"cohort\", name) &\n                              !grepl(\"age\", name) & \n                              !grepl(\"fish\", name) &\n                              !grepl(\"sex\", name))  \n  \n  \n  links$IDsource &lt;- match(links$source, nodes$name) - 1\n  links$IDtarget &lt;- match(links$target, nodes$name) - 1\n  \n  color_scale &lt;- data.frame(\n    domain = c(\"exposure\", \"lc\", \"biomarker\", \n               \"outcome\", \"TRUE\", \"FALSE\"), \n    range = c(G_color, X_color, \n              Z_color, Y_color, pos_link_color, neg_link_color))\n  \n  sankey_df = list(links = links, \n                   nodes = nodes)\n  \n  # p &lt;- sankeyNetwork(\n  #   Links = sankey_df$links, \n  #   Nodes = sankey_df$nodes, \n  #   Source = \"IDsource\", \n  #   Target = \"IDtarget\",\n  #   Value = \"value\", \n  #   NodeID = \"name\", \n  #   colourScale = JS(sprintf(\"d3.scaleOrdinal()\\n .domain(%s)\\n .range(%s)\\n \", \n  #                            jsonlite::toJSON(color_scale$domain), \n  #                            jsonlite::toJSON(color_scale$range))), \n  #   LinkGroup = \"group\", \n  #   NodeGroup = \"group\", \n  #   sinksRight = FALSE, \n  #   fontSize = fontsize)\n  # p\n  return(sankey_df)\n}\n\n\n# lucid_fit1 &lt;- fit1 \n# lucid_fit2 &lt;- fit2 \n# lucid_fit3 &lt;- fit3 \n\n# sankey_in_serial Function ----\nsankey_in_serial &lt;- function(lucid_fit1, lucid_fit2, lucid_fit3, color_pal_sankey, text_size = 15) {\n  \n  # 1. Get sankey dataframes ----\n  sankey_dat1 &lt;- get_sankey_df(lucid_fit1)\n  sankey_dat2 &lt;- get_sankey_df(lucid_fit2)\n  sankey_dat3 &lt;- get_sankey_df(lucid_fit3)\n  \n  n_omics_1 &lt;- length(lucid_fit1$var.names$Znames)\n  n_omics_2 &lt;- length(lucid_fit2$var.names$Znames)\n  n_omics_3 &lt;- length(lucid_fit3$var.names$Znames)\n  \n  # combine link data\n  lnks1_methylation &lt;- sankey_dat1[[\"links\"]] %&gt;% mutate(analysis = \"1_methylation\")\n  lnks2_miRNA  &lt;- sankey_dat2[[\"links\"]] %&gt;% mutate(analysis = \"2_miRNA\")\n  lnks3_transcription    &lt;- sankey_dat3[[\"links\"]] %&gt;% mutate(analysis = \"3_transcript\")\n  links &lt;- bind_rows(lnks1_methylation, lnks2_miRNA, lnks3_transcription)\n  \n  # combine node data\n  nodes1_methylation &lt;- sankey_dat1[[\"nodes\"]] %&gt;% mutate(analysis = \"1_methylation\")\n  nodes2_miRNA  &lt;- sankey_dat2[[\"nodes\"]] %&gt;% mutate(analysis = \"2_miRNA\")\n  nodes3_transcription    &lt;- sankey_dat3[[\"nodes\"]] %&gt;% mutate(analysis = \"3_transcript\")\n  nodes &lt;- bind_rows(nodes1_methylation, nodes2_miRNA, nodes3_transcription)\n  \n  \n  # 2. Modify analysis 1 ----\n  # For analysis 1, latent clusters need to be renamed to names from analysis 2:\n  ## 2.1 Get new and original latent cluster names (from the next analysis) ----\n  names_clusters_1 &lt;- data.frame(\n    name_og = c(\"Latent Cluster1\", \"Latent Cluster2\"), \n    name_new = c(\"&lt;b&gt;Methylation\\nProfile 0&lt;/b&gt;\", \"&lt;b&gt;Methylation\\nProfile 1&lt;/b&gt;\"))\n  \n  ## 2.2 Change link names ----\n  # Change link names and \n  lnks1_methylation_new &lt;- sankey_dat1[[\"links\"]] %&gt;%\n    mutate(\n      analysis = \"1_methylation\",\n      source = case_when(\n        source == names_clusters_1$name_og[1] ~ names_clusters_1$name_new[1],\n        source == names_clusters_1$name_og[2] ~ names_clusters_1$name_new[2],\n        TRUE ~ source),\n      target = case_when(\n        target == names_clusters_1$name_og[1] ~ names_clusters_1$name_new[1],\n        target == names_clusters_1$name_og[2] ~ names_clusters_1$name_new[2],\n        TRUE ~ target)) %&gt;%\n    filter(target != \"outcome\")\n  \n  ## 2.3 Change node names ----\n  # first, change latent cluster names to analysis specific cluster names\n  nodes1_methylation_new &lt;- sankey_dat1[[\"nodes\"]] %&gt;%\n    mutate(\n      name = case_when(\n        name == names_clusters_1$name_og[1] ~ names_clusters_1$name_new[1],\n        name == names_clusters_1$name_og[2] ~ names_clusters_1$name_new[2],\n        TRUE ~ name), \n      group = if_else(group == \"biomarker\", \"CpG\", as.character(group))) %&gt;%\n    filter(group != \"outcome\")\n  \n  \n  # Visualize\n  # sankeyNetwork(\n  #   Links = lnks1_methylation_new,\n  #   Nodes = nodes1_methylation_new,\n  #   Source = \"IDsource\", Target = \"IDtarget\",\n  #   Value = \"value\", NodeID = \"name\", LinkGroup = \"group\", NodeGroup = \"group\",\n  #   sinksRight = FALSE)\n  \n  \n  # 3. Modify analysis 2 ----\n  # For analysis 2, latent clusters need to be renamed to names from analysis 3:\n  ## 3.1 Get new and og latent cluster names ----\n  names_clusters_2 &lt;- data.frame(\n    name_og = c(\"Latent Cluster1\", \"Latent Cluster2\"), \n    name_new = c(\"&lt;b&gt;miRNA\\nProfile 0&lt;/b&gt;\", \"&lt;b&gt;miRNA\\nProfile 1&lt;/b&gt;\"))\n  \n  ## 3.2 Change cluster names ----\n  lnks2_miRNA_new &lt;- sankey_dat2[[\"links\"]] %&gt;% \n    mutate(\n      analysis = \"2_miRNA\", \n      source = case_when(\n        source == names_clusters_2$name_og[1] ~ names_clusters_2$name_new[1], \n        source == names_clusters_2$name_og[2] ~ names_clusters_2$name_new[2], \n        TRUE ~ source), \n      target = case_when(\n        target == names_clusters_2$name_og[1] ~ names_clusters_2$name_new[1], \n        target == names_clusters_2$name_og[2] ~ names_clusters_2$name_new[2], \n        TRUE ~ target)) %&gt;%\n    filter(target != \"outcome\")\n  \n  ## 3.3 Change node names ----\n  nodes2_miRNA_new &lt;- sankey_dat2[[\"nodes\"]] %&gt;% \n    mutate(\n      name = case_when(\n        name == names_clusters_2$name_og[1] ~ names_clusters_2$name_new[1], \n        name == names_clusters_2$name_og[2] ~ names_clusters_2$name_new[2], \n        TRUE ~ name), \n      group = case_when(group == \"exposure\" ~ \"lc\", \n                        group == \"biomarker\" ~ \"miRNA\",\n                        TRUE ~ as.character(group))) %&gt;%\n    filter(name != \"outcome\")\n  \n  # Visualize\n  # sankeyNetwork(\n  #   Links = lnks2_transcript_new, \n  #   Nodes = nodes2_transcript_new,\n  #   Source = \"IDsource\", Target = \"IDtarget\",\n  #   Value = \"value\", NodeID = \"name\", \n  #   LinkGroup = \"group\", NodeGroup = \"group\",\n  #   sinksRight = FALSE)\n  ##\n  \n  # 4. Modify analysis 3 ----\n  # For analysis 2, latent clusters need to be renamed to names from analysis 3:\n  ## 4.1 Get new and og latent cluster names ----\n  names_clusters_3 &lt;- tibble(\n    name_og = c(\"Latent Cluster1\", \"Latent Cluster2\"),\n    name_new = c(\"&lt;b&gt;Transcriptome\\nProfile 0&lt;/b&gt;\", \"&lt;b&gt;Transcriptome\\nProfile 1&lt;/b&gt;\")) \n  \n  \n  ## 4.2 Change cluster names ----\n  lnks3_transcript_new &lt;- sankey_dat3[[\"links\"]] %&gt;% \n    mutate(\n      analysis = \"3_transcript\", \n      source = case_when(\n        source == names_clusters_3$name_og[1] ~ names_clusters_3$name_new[1], \n        source == names_clusters_3$name_og[2] ~ names_clusters_3$name_new[2], \n        TRUE ~ source), \n      target = case_when(\n        target == names_clusters_3$name_og[1] ~ names_clusters_3$name_new[1], \n        target == names_clusters_3$name_og[2] ~ names_clusters_3$name_new[2], \n        TRUE ~ target))\n  \n  ## 4.3 Change node names ----\n  nodes3_transcript_new &lt;- sankey_dat3[[\"nodes\"]] %&gt;% \n    mutate(\n      name = case_when(\n        name == names_clusters_3$name_og[1] ~ names_clusters_3$name_new[1], \n        name == names_clusters_3$name_og[2] ~ names_clusters_3$name_new[2], \n        TRUE ~ name), \n      group = case_when(group == \"exposure\" ~ \"lc\", \n                        group == \"biomarker\" ~ \"TC\",\n                        TRUE ~ as.character(group)))\n  \n  # Test/Visualize\n  # sankeyNetwork(\n  #   Links = lnks3_protein_new, \n  #   Nodes = nodes3_protein_new,\n  #   Source = \"IDsource\", Target = \"IDtarget\",\n  #   Value = \"value\", NodeID = \"name\", LinkGroup = \"group\", NodeGroup = \"group\",\n  #   sinksRight = FALSE)\n  \n  \n  \n  # 5. Combine analysis 1-3 ----\n  \n  ## 5.1 Final Links ----\n  links_all_1 &lt;- bind_rows(lnks1_methylation_new, \n                           lnks2_miRNA_new,\n                           lnks3_transcript_new) %&gt;%\n    dplyr::select(-IDsource, -IDtarget)\n  \n  \n  ### 5.1.1 Arrange by magnitude ----\n  omics_priority &lt;- links_all_1 %&gt;% \n    filter(str_detect(source, \"Profile 0\"), \n                    str_detect(target, \"Profile 0\", negate = TRUE), \n                    str_detect(target, \"Profile 1\", negate = TRUE), \n                    str_detect(target, \"outcome\", negate = TRUE)) %&gt;%\n    group_by(source) %&gt;%\n    arrange(desc(group), desc(value), .by_group = TRUE) %&gt;%\n    mutate(omics_order = row_number()) %&gt;%\n    ungroup() %&gt;%\n    dplyr::select(target, omics_order)\n  \n  \n  \n  links_all &lt;- links_all_1 %&gt;%\n    left_join(omics_priority) %&gt;%\n    mutate(\n      # arrange_me = if_else(is.na(omics_order), \n      #                           \"dont_arrange\", \n      #                           \"arrange\"), \n      row_num = row_number(), \n      # row_num_order_comb = if_else(is.na(omics_order), \n      #                              row_num, \n      #                              omics_order), \n      row_num_to_add = if_else(is.na(omics_order), \n                               as.numeric(row_num), \n                               NA_real_) %&gt;%\n        zoo::na.locf(),\n      order = if_else(is.na(omics_order), \n                      row_num_to_add, \n                      row_num_to_add+omics_order)\n    ) %&gt;%\n    arrange(order)\n  \n  \n  ### 5.1.2 Get new source and target IDs ----\n  # First, combine all layers, get unique identifier\n  node_ids &lt;- tibble(name = unique(c(unique(links_all$source), \n                                     unique(links_all$target)))) %&gt;%\n    mutate(ID = row_number()-1)\n  \n  # Then combine with original data \n  links_new &lt;- links_all %&gt;%\n    left_join(node_ids, by = c(\"source\" = \"name\")) %&gt;%\n    dplyr::rename(IDsource = ID) %&gt;%\n    left_join(node_ids, by = c(\"target\" = \"name\")) %&gt;%\n    dplyr::rename(IDtarget = ID)\n  \n  \n  ## 5.2 Final Nodes ----\n  nodes_new &lt;- node_ids %&gt;%\n    dplyr::select(name) %&gt;%\n    left_join(bind_rows(nodes1_methylation_new, \n                                 nodes2_miRNA_new,\n                                 nodes3_transcript_new))\n  # remove duplicates \n  nodes_new_nodup &lt;- nodes_new[!base::duplicated(nodes_new),] %&gt;%\n    base::as.data.frame()\n  \n  \n  # 6. Plotly Version ----\n  \n  # Add color scheme to nodes\n  nodes_new_plotly &lt;- nodes_new_nodup %&gt;% \n    left_join(color_pal_sankey) %&gt;%\n    mutate(\n      x = case_when(\n        group == \"exposure\" ~ 0,\n        str_detect(name, \"Methylation\") ~ 1/5, \n        str_detect(name, \"miRNA\") | \n          str_detect(group, \"CpG\") ~ 2/5, \n        str_detect(name, \"Transcriptome\") | \n          str_detect(group, \"miRNA\") ~ 3/5, \n        str_detect(group, \"TC\") ~  4/5, \n        str_detect(group, \"outcome\") ~ 4.5/5, \n      ))\n  \n  \n  ## 6.2 Get links for Plotly, set color ----\n  links_new &lt;- links_new  %&gt;%\n    mutate(\n      link_color = case_when(\n        # Ref link color\n        value == 0 ~     \"#f3f6f4\", \n        # Methylation \n        str_detect(target, \"outcome\") &  group == TRUE  ~  \"red\",\n        \n        str_detect(source, \"Transcriptome\") &  group == TRUE  ~  \"#bf9000\",\n        str_detect(source, \"Transcriptome\") &  group == FALSE ~  \"#ffd966\",\n        # Transcriptome\n        str_detect(source, \"Methylation\") &  group == TRUE  ~  \"#38761d\",\n        str_detect(source, \"Methylation\") &  group == FALSE ~  \"#b6d7a8\",\n        # proteome\n        str_detect(source, \"miRNA\") &  group == TRUE  ~  \"#a64d79\",\n        str_detect(source, \"miRNA\") &  group == FALSE ~  \"#ead1dc\",\n        \n        links_new$group == FALSE ~ \"#d9d2e9\", # Negative association\n        links_new$group == TRUE ~  \"red\")) # Positive association\n  \n  plotly_link &lt;- list(\n    source = links_new$IDsource,\n    target = links_new$IDtarget,\n    value = links_new$value+.00000000000000000000001, \n    color = links_new$link_color)  \n  \n  \n  # Get list of nodes for Plotly\n  plotly_node &lt;- list(\n    label = nodes_new_plotly$name, \n    color = nodes_new_plotly$color,\n    pad = 15,\n    thickness = 20,\n    line = list(color = \"black\",width = 0.5), \n    x = nodes_new_plotly$x, \n    y = c(0.01, \n          0.1, 0.3, # Methylation clusters\n          .45, .55, # Transcriptome clusters\n          .80, .95, # Proteome clusters\n          seq(from = .01, to = 1, by = 0.035)[1:n_omics_1], # Cpgs (10 total)\n          seq(from = 0.35, to = 1, by = 0.025)[1:n_omics_2], # miRNA (8 total)\n          seq(from = 0.75, to = 1, by = 0.03)[1:n_omics_3], # Transcript (10 total)\n          .95\n    ))\n  \n  \n  ## 6.3 Plot Figure ----\n  fig &lt;- plot_ly(\n    type = \"sankey\",\n    domain = list(\n      x =  c(0,1),\n      y =  c(0,1)),\n    orientation = \"h\",\n    node = plotly_node,\n    link = plotly_link)\n  \n  (fig &lt;- fig %&gt;% layout(\n    # title = \"Basic Sankey Diagram\",\n    font = list(\n      size = text_size\n    ))\n  )\n  \n  return(fig)\n}\n\n\n\n\n6.3.4 Plot Omics Profile\n\n\nCode\n#' Plot of Omics profiles for each cluster using LUCID\n#' \n#' Given an object of class from LUCID\n#'\n#' @param fit an object of class from LUCID\n#' @param integration_type type of integreation,, \"Early\" or \"Intermediate\"\n#'\n#' @return a figure of Omics profiles for each cluster using LUCID\n#'\n#' @import dplyr\n#' @importFrom ggplot2 ggplot\n\n\nplot_omics_profiles &lt;- function(fit, integration_type) {\n  if(integration_type == \"Early\"){\n    M_mean = as.data.frame(fit$pars$mu)\n    M_mean$cluster = as.factor(1:2)\n    # Reshape the data\n    M_mean_melt &lt;- M_mean %&gt;% \n      pivot_longer(cols = -cluster, names_to = \"variable\", values_to = \"value\")\n    \n    M_mean_melt &lt;- M_mean_melt %&gt;% \n      mutate(cluster = paste0(\"Cluster \", cluster))\n    # add color label for omics layer\n    M_mean_melt = M_mean_melt %&gt;%\n      mutate(color_label = case_when(str_detect(variable,  \"cg\") ~ \"1\", \n                                     str_detect(variable, \"tc\") ~ \"2\", \n                                     TRUE ~ \"3\"))\n    \n    fig &lt;- ggplot(M_mean_melt, \n                  aes(fill = color_label, y = value, x = variable)) +\n      geom_bar(position=\"dodge\", stat=\"identity\") +\n      ggtitle(\"Omics profiles for the two latent clusters\") +\n      facet_grid(rows = vars(cluster), scales = \"free_y\") +\n      theme(legend.position=\"none\") +\n      geom_hline(yintercept = 0) +\n      xlab(\"\") +\n      theme(text = element_text(size=10),\n            axis.text.x = element_text(angle = 90, vjust = 1,\n                                       hjust = 1),\n            plot.margin = margin(10, 10, 10, 80),\n            panel.background = element_rect(fill=\"white\"), \n            strip.background = element_rect(fill = \"white\"),\n            axis.line.x = element_line(color = \"black\"),\n            axis.line.y = element_line(color = \"black\"),) +\n      scale_fill_manual(values = c(\"#2fa4da\", \"#A77E69\", \"#e7b6c1\"))\n  } else if(integration_type == \"Intermediate\"){\n    M_mean = as_tibble(fit$res_Mu_Sigma$Mu[[1]], rownames = \"variable\") %&gt;%\n      bind_rows(as_tibble(fit$res_Mu_Sigma$Mu[[2]], rownames = \"variable\")) %&gt;%\n      bind_rows(as_tibble(fit$res_Mu_Sigma$Mu[[3]], rownames = \"variable\"))\n    \n    # Reorder results because mirna order is reversed\n    M_mean1 &lt;- M_mean %&gt;% \n      left_join(meta_df, by = c(\"variable\" = \"ftr_name\")) %&gt;%\n      mutate(`Low Risk`  =  if_else(omic_layer == \"miRna\", V2, V1), \n             `High Risk` =  if_else(omic_layer == \"miRna\", V1, V2)) %&gt;%\n      dplyr::select(-c(\"V1\", \"V2\"))\n    \n    # Pivot longer for figure \n    M_mean_l &lt;- M_mean1 %&gt;% \n      pivot_longer(cols = c(`Low Risk`, `High Risk`),\n                   names_to = \"cluster\",\n                   values_to = \"value\")\n    \n    # add color label for omics layer\n    M_mean2 = M_mean_l %&gt;%\n      mutate(color_label = case_when(omic_layer == \"methylome\" ~ \"1\", \n                                     omic_layer == \"transcriptome\" ~ \"2\", \n                                     omic_layer == \"miRna\" ~ \"3\"), \n             low_high = if_else(str_detect(cluster, \"Low\"), 0,1),\n             omic = if_else(omic_layer == \"miRna\", \n                            \"miR\",\n                            str_sub(omic_layer, end = 1) %&gt;% toupper()),\n             omic_cluster = str_c(omic, low_high))\n    \n    # Filter only the top ## differential expressed features \n    M_mean2_top &lt;- M_mean2 %&gt;% \n      group_by(variable) %&gt;% \n      filter(abs(value) == max(abs(value))) %&gt;% \n      ungroup() %&gt;% \n      arrange(max(abs(value))) %&gt;% \n      group_by(omic_layer) %&gt;% \n      slice_head(n=12) %&gt;%\n      ungroup()\n    \n    # Plots top 12 features\n    fig &lt;- ggplot(M_mean2  %&gt;% filter(variable %in% M_mean2_top$variable),\n                  aes(fill = color_label, y = value, x = variable)) +\n      geom_bar(position=\"dodge\", stat=\"identity\") +\n      ggtitle(\"Omics profiles for 2 latent clusters - Lucid in Parallel\") +\n      facet_grid(rows = vars(cluster),\n                 cols = vars(omic_layer), scales = \"free_x\", space = \"free\") +\n      theme(legend.position=\"none\") +\n      geom_hline(yintercept = 0) +\n      xlab(\"\") +\n      theme(text = element_text(size=10),\n            axis.text.x = element_text(angle = 90, vjust = 1,\n                                       hjust = 1),\n            plot.margin = margin(10, 10, 10, 80),\n            panel.background = element_rect(fill=\"white\"),\n            strip.background = element_rect(fill = \"white\"),\n            axis.line.x = element_line(color = \"black\"),\n            axis.line.y = element_line(color = \"black\"),) +\n      scale_fill_manual(values = c(\"#2fa4da\", \"#A77E69\", \"#e7b6c1\"))\n  }\n  \n  return(fig)\n}"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "He, Jingxuan, and Chubing Zeng. 2023. “Xtune: Regularized\nRegression with Feature-Specific Penalties Integrating External\nInformation.” Computer Program. https://github.com/JingxuanH/xtune.\n\n\nLock, E. F., K. A. Hoadley, J. S. Marron, and A. B. Nobel. 2013.\n“JOINT AND INDIVIDUAL VARIATION EXPLAINED (JIVE) FOR INTEGRATED\nANALYSIS OF MULTIPLE DATA TYPES.” Journal Article. Ann Appl\nStat 7 (1): 523–42. https://doi.org/10.1214/12-aoas597.\n\n\nTofighi, D., and D. P. MacKinnon. 2011. “RMediation: An r Package\nfor Mediation Analysis Confidence Intervals.” Journal Article.\nBehav Res Methods 43 (3): 692–700. https://doi.org/10.3758/s13428-011-0076-x.\n\n\nVrijheid, Martine, Rémy Slama, Oliver Robinson, Leda Chatzi, Muireann\nCoen, Peter van den Hazel, Cathrine Thomsen, et al. 2014. “The\nHuman Early-Life Exposome (HELIX): Project Rationale and Design.”\nJournal Article. Environmental Health Perspectives 122 (6):\n535–44. https://doi.org/10.1289/ehp.1307204.\n\n\nZeng, C., D. C. Thomas, and J. P. Lewinger. 2021. “Incorporating\nPrior Knowledge into Regularized Regression.” Journal Article.\nBioinformatics 37 (4): 514–21. https://doi.org/10.1093/bioinformatics/btaa776.\n\n\nZhang, H., Y. Zheng, Z. Zhang, T. Gao, B. Joyce, G. Yoon, W. Zhang, et\nal. 2016. “Estimating and Testing High-Dimensional Mediation\nEffects in Epigenetic Studies.” Journal Article.\nBioinformatics 32 (20): 3150–54. https://doi.org/10.1093/bioinformatics/btw351."
  }
]